{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "325d39d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.25.73 requires botocore==1.27.72, but you have botocore 1.27.73 which is incompatible.\n",
      "aiobotocore 2.0.1 requires botocore<1.22.9,>=1.22.8, but you have botocore 1.27.73 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q \"sagemaker>=2.70.0\" \"transformers==4.11.0\" --upgrade\n",
    "\n",
    "!pip install -q \"datasets==1.13\" --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdbb4d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\r\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ac43a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af5dd140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07171982",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b431fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups(subset=\"all\", shuffle=True, remove=(\"headers\", \"footers\", \"quotes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56735ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = dataset.data\n",
    "labels = dataset.target\n",
    "df=pd.DataFrame({\"documents\":documents,\"labels\":labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a19bab66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nI am sure some bashers of Pens fans are pr...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My brother is in the market for a high-perform...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\n\\n\\tFinally you said what you dream abou...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nThink!\\n\\nIt's the SCSI card doing the DMA t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1)    I have an old Jasmine drive which I cann...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18841</th>\n",
       "      <td>DN&gt; From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18842</th>\n",
       "      <td>\\nNot in isolated ground recepticles (usually ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18843</th>\n",
       "      <td>I just installed a DX2-66 CPU in a clone mothe...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18844</th>\n",
       "      <td>\\nWouldn't this require a hyper-sphere.  In 3-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18845</th>\n",
       "      <td>After a tip from Gary Crum (crum@fcom.cc.utah....</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18846 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               documents  labels\n",
       "0      \\n\\nI am sure some bashers of Pens fans are pr...      10\n",
       "1      My brother is in the market for a high-perform...       3\n",
       "2      \\n\\n\\n\\n\\tFinally you said what you dream abou...      17\n",
       "3      \\nThink!\\n\\nIt's the SCSI card doing the DMA t...       3\n",
       "4      1)    I have an old Jasmine drive which I cann...       4\n",
       "...                                                  ...     ...\n",
       "18841  DN> From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...      13\n",
       "18842  \\nNot in isolated ground recepticles (usually ...      12\n",
       "18843  I just installed a DX2-66 CPU in a clone mothe...       3\n",
       "18844  \\nWouldn't this require a hyper-sphere.  In 3-...       1\n",
       "18845  After a tip from Gary Crum (crum@fcom.cc.utah....       7\n",
       "\n",
       "[18846 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "752d6239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re,string\n",
    "\n",
    "def text_cleaner(text):\n",
    "\n",
    "    '''some text cleaning method'''\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "\n",
    "    text = re.sub('\\n', '', text)\n",
    "\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "583aa0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"documents\"]=df[\"documents\"].apply(text_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "198d8967",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.head(1100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb9f9e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ad6b769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am sure some bashers of pens fans are pretty...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my brother is in the market for a highperforma...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\tfinally you said what you dream about medite...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thinkits the scsi card doing the dma transfers...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i have an old jasmine drive which i cannot...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>i am hoping to produce the first update of the...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>in article  manesmagpielinknetcom steve     i...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>sorry malcolm but i rather believe jesus than...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>i have placed a new release of my axe editor i...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>all children are born pure ie without sinhowev...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              documents  labels\n",
       "0     i am sure some bashers of pens fans are pretty...      10\n",
       "1     my brother is in the market for a highperforma...       3\n",
       "2     \\tfinally you said what you dream about medite...      17\n",
       "3     thinkits the scsi card doing the dma transfers...       3\n",
       "4         i have an old jasmine drive which i cannot...       4\n",
       "...                                                 ...     ...\n",
       "1095  i am hoping to produce the first update of the...       9\n",
       "1096   in article  manesmagpielinknetcom steve     i...      16\n",
       "1097   sorry malcolm but i rather believe jesus than...      19\n",
       "1098  i have placed a new release of my axe editor i...       5\n",
       "1099  all children are born pure ie without sinhowev...      15\n",
       "\n",
       "[1100 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42496a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdf27278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>oh and us with the big degrees dont got imagin...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>i have version  which i believe was needed for...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>sutcliffe gives up  hrs gonzales  palmer  and ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>\\tok ill admit it  i cant find a quote with my...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>recently i have been getting a cmos checksum e...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>not necessarily  it could mean that or it coul...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>dont worry about this  theyll drop you like a ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>april   eff analysis of clinton privacy and se...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>i have the same problem someone suggested it m...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>ok  i have a record that shows a iisi with and...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             documents  labels\n",
       "232  oh and us with the big degrees dont got imagin...      14\n",
       "201  i have version  which i believe was needed for...       4\n",
       "474  sutcliffe gives up  hrs gonzales  palmer  and ...       9\n",
       "722  \\tok ill admit it  i cant find a quote with my...      17\n",
       "378  recently i have been getting a cmos checksum e...       3\n",
       "..                                                 ...     ...\n",
       "666  not necessarily  it could mean that or it coul...       9\n",
       "54   dont worry about this  theyll drop you like a ...       7\n",
       "714  april   eff analysis of clinton privacy and se...      11\n",
       "501  i have the same problem someone suggested it m...       2\n",
       "466  ok  i have a record that shows a iisi with and...       4\n",
       "\n",
       "[1100 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ce7fafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = df.shape[0]\n",
    "train = int(.8* rows)\n",
    "test = rows-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cce58298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((880, 2), (220, 2))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:train].shape,df[train:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57da66fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:train].to_csv('train.csv'\n",
    "                          ,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19c7a2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Validation Set\n",
    "df[train:].to_csv('test.csv'\n",
    "                          ,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ca264be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>oh and us with the big degrees dont got imagin...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>i have version  which i believe was needed for...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>sutcliffe gives up  hrs gonzales  palmer  and ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>\\tok ill admit it  i cant find a quote with my...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>recently i have been getting a cmos checksum e...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>not necessarily  it could mean that or it coul...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>dont worry about this  theyll drop you like a ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>april   eff analysis of clinton privacy and se...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>i have the same problem someone suggested it m...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>ok  i have a record that shows a iisi with and...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             documents  labels\n",
       "232  oh and us with the big degrees dont got imagin...      14\n",
       "201  i have version  which i believe was needed for...       4\n",
       "474  sutcliffe gives up  hrs gonzales  palmer  and ...       9\n",
       "722  \\tok ill admit it  i cant find a quote with my...      17\n",
       "378  recently i have been getting a cmos checksum e...       3\n",
       "..                                                 ...     ...\n",
       "666  not necessarily  it could mean that or it coul...       9\n",
       "54   dont worry about this  theyll drop you like a ...       7\n",
       "714  april   eff analysis of clinton privacy and se...      11\n",
       "501  i have the same problem someone suggested it m...       2\n",
       "466  ok  i have a record that shows a iisi with and...       4\n",
       "\n",
       "[1100 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d5aadde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     labels\n",
       "232      14\n",
       "201       4\n",
       "474       9\n",
       "722      17\n",
       "378       3\n",
       "..      ...\n",
       "666       9\n",
       "54        7\n",
       "714      11\n",
       "501       2\n",
       "466       4\n",
       "\n",
       "[1100 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"labels\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f777fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ea4d5f2",
   "metadata": {},
   "source": [
    "# Sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b82c704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "# from sagemaker.sklearn.estimator import SKLearn\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "region = sagemaker_session.boto_session.region_name\n",
    "import os\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff92ccab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-east-2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "004e2983",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'agtimeseries'\n",
    "\n",
    "training_folder = r'mme-hf-folder/train'\n",
    "test_folder = r'mme-hf-folder/test'\n",
    "model_folder1 = r'mme-hf-folder/model1/'\n",
    "script_code_folder1=r\"mme-hf-folder/scriptcode1\"\n",
    "\n",
    "model_folder2 = r'mme-hf-folder/model2/'\n",
    "script_code_folder2=r\"mme-hf-folder/scriptcode2\"\n",
    "\n",
    "\n",
    "model_folder3 = r'mme-hf-folder/model3/'\n",
    "script_code_folder3=r\"mme-hf-folder/scriptcode3\"\n",
    "\n",
    "training_data_loc = r's3://' + bucket_name + r'/' + training_folder\n",
    "testing_data_loc = r's3://' + bucket_name + r'/' + test_folder\n",
    "\n",
    "model_data_loc1 = r's3://' + bucket_name + r'/' + model_folder1\n",
    "script_code_loc1=r's3://' + bucket_name + r'/' + script_code_folder1\n",
    "\n",
    "\n",
    "model_data_loc2 = r's3://' + bucket_name + r'/' + model_folder2\n",
    "script_code_loc2=r's3://' + bucket_name + r'/' + script_code_folder2\n",
    "\n",
    "model_data_loc3 = r's3://' + bucket_name + r'/' + model_folder3\n",
    "script_code_loc3=r's3://' + bucket_name + r'/' + script_code_folder3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3dbdc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://agtimeseries/mme-hf-folder/train'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9c070c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file=\"train.csv\"\n",
    "test_file=\"test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54b92629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://agtimeseries/mme-hf-folder/train/train.csv'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker_session.upload_data(train_file,\n",
    "                              bucket=bucket_name, \n",
    "                              key_prefix=training_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9deefc56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://agtimeseries/mme-hf-folder/test/test.csv'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker_session.upload_data(test_file, \n",
    "                              bucket=bucket_name, \n",
    "                              key_prefix=test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71be1639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://agtimeseries/mme-hf-folder/model1/'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data_loc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64b49245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace,TrainingCompilerConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06ac824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler_config=TrainingCompilerConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a3fb58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0f774fb",
   "metadata": {},
   "source": [
    "# Estimator: 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01c75772",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters={'epochs': 1,                                    # number of training epochs\n",
    "                 'train_batch_size': 8,                         # batch size for training\n",
    "                 'eval_batch_size': 8,                          #batch size for testing\n",
    "                 \"model_id\" :'bert-base-uncased'                #pretrained model name from hf\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2945e78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator1 = HuggingFace(\n",
    "    entry_point          = 'script3.py',       # script code to run the model      \n",
    "    source_dir           = 'code/',\n",
    "    instance_type        = 'ml.p3.2xlarge',    # instances type used for the training job\n",
    "    instance_count       = 1,                  # the number of instances used for training\n",
    "    base_job_name        = \"bert-model\",       # the name of the training job     \n",
    "    role                 = role,               # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    transformers_version = '4.11.0',           # the transformers version used in the training job\n",
    "    pytorch_version      = '1.9.0',            # the pytorch_version version used in the training job\n",
    "    py_version           = 'py38',             # the python version used in the training job\n",
    "    compiler_config      = compiler_config,    # the compiler configuration used in the training job\n",
    "    hyperparameters      = hyperparameters,    # the hyperparameter used for running the training job\n",
    "    disable_profiler     = True,               # whether to disable the profiler during training used to gain maximum performance\n",
    "    debugger_hook_config = False,              # whether to enable the debugger hook during training used to gain maximum performance\n",
    "    output_path          = model_data_loc1,     # s3 location where the final fine-tuned model will be saved \n",
    "    code_location        = script_code_loc1     # s3 location where the estimator will push the script code\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc325eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'training': training_data_loc, 'testing': testing_data_loc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b43d3d83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: bert-model-2023-06-04-07-51-04-231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-04 07:51:04 Starting - Starting the training job...\n",
      "2023-06-04 07:51:29 Starting - Preparing the instances for training......\n",
      "2023-06-04 07:52:30 Downloading - Downloading input data...\n",
      "2023-06-04 07:52:50 Training - Downloading the training image...........................\n",
      "2023-06-04 07:57:36 Training - Training image download completed. Training in progress....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-06-04 07:58:00,360 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-06-04 07:58:00,388 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-06-04 07:58:00,391 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-06-04 07:58:00,661 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_training_compiler_debug_mode\": false,\n",
      "        \"sagemaker_training_compiler_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"testing\": \"/opt/ml/input/data/testing\",\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 1,\n",
      "        \"eval_batch_size\": 8,\n",
      "        \"model_id\": \"bert-base-uncased\",\n",
      "        \"train_batch_size\": 8\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"testing\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"bert-model-2023-06-04-07-51-04-231\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://agtimeseries/mme-hf-folder/scriptcode1/bert-model-2023-06-04-07-51-04-231/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"script3\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"script3.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":1,\"eval_batch_size\":8,\"model_id\":\"bert-base-uncased\",\"train_batch_size\":8}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=script3.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_training_compiler_debug_mode\":false,\"sagemaker_training_compiler_enabled\":true}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"testing\",\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=script3\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://agtimeseries/mme-hf-folder/scriptcode1/bert-model-2023-06-04-07-51-04-231/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_training_compiler_debug_mode\":false,\"sagemaker_training_compiler_enabled\":true},\"channel_input_dirs\":{\"testing\":\"/opt/ml/input/data/testing\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":1,\"eval_batch_size\":8,\"model_id\":\"bert-base-uncased\",\"train_batch_size\":8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"bert-model-2023-06-04-07-51-04-231\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://agtimeseries/mme-hf-folder/scriptcode1/bert-model-2023-06-04-07-51-04-231/source/sourcedir.tar.gz\",\"module_name\":\"script3\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"script3.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"1\",\"--eval_batch_size\",\"8\",\"--model_id\",\"bert-base-uncased\",\"--train_batch_size\",\"8\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TESTING=/opt/ml/input/data/testing\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_HP_EVAL_BATCH_SIZE=8\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_ID=bert-base-uncased\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_BATCH_SIZE=8\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python script3.py --epochs 1 --eval_batch_size 8 --model_id bert-base-uncased --train_batch_size 8\u001b[0m\n",
      "\u001b[34m[2023-06-04 07:58:00.718 torch.__training_compiler__.TrainingCompilerConfig INFO] Found configuration for Training Compiler. Compiler will be configured during import of torch_xla.\u001b[0m\n",
      "\u001b[34m[2023-06-04 07:58:01.763 torch_xla.__training_compiler__.TrainingCompilerConfig INFO] Configuring SM Training Compiler...\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 28.0/28.0 [00:00<00:00, 39.6kB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/570 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 570/570 [00:00<00:00, 799kB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/226k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 226k/226k [00:00<00:00, 38.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/455k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 455k/455k [00:00<00:00, 55.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/420M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading:   1%|▏         | 6.08M/420M [00:00<00:06, 63.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   3%|▎         | 13.1M/420M [00:00<00:06, 69.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   5%|▍         | 20.1M/420M [00:00<00:05, 71.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   6%|▋         | 27.1M/420M [00:00<00:05, 72.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   8%|▊         | 34.3M/420M [00:00<00:05, 73.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  10%|▉         | 41.4M/420M [00:00<00:05, 73.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  12%|█▏        | 48.5M/420M [00:00<00:05, 74.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  13%|█▎        | 55.7M/420M [00:00<00:05, 74.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  15%|█▍        | 62.7M/420M [00:00<00:05, 74.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  17%|█▋        | 69.8M/420M [00:01<00:04, 74.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  18%|█▊        | 76.9M/420M [00:01<00:04, 74.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  20%|█▉        | 84.0M/420M [00:01<00:04, 74.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  22%|██▏       | 91.1M/420M [00:01<00:04, 74.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  23%|██▎       | 98.2M/420M [00:01<00:04, 74.4MB/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mDownloading:  25%|██▌       | 105M/420M [00:01<00:04, 74.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  27%|██▋       | 113M/420M [00:01<00:04, 74.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  29%|██▊       | 120M/420M [00:01<00:04, 74.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  30%|███       | 127M/420M [00:01<00:04, 74.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  32%|███▏      | 134M/420M [00:01<00:04, 74.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  34%|███▎      | 141M/420M [00:02<00:03, 74.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  35%|███▌      | 148M/420M [00:02<00:03, 74.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  37%|███▋      | 155M/420M [00:02<00:03, 74.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  39%|███▊      | 162M/420M [00:02<00:03, 74.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  40%|████      | 170M/420M [00:02<00:03, 74.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  42%|████▏     | 177M/420M [00:02<00:03, 74.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  44%|████▍     | 184M/420M [00:02<00:03, 74.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  45%|████▌     | 191M/420M [00:02<00:03, 74.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  47%|████▋     | 198M/420M [00:02<00:03, 74.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  49%|████▉     | 205M/420M [00:02<00:03, 74.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  51%|█████     | 212M/420M [00:03<00:02, 74.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  52%|█████▏    | 219M/420M [00:03<00:02, 74.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  54%|█████▍    | 226M/420M [00:03<00:02, 74.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  56%|█████▌    | 234M/420M [00:03<00:02, 74.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  57%|█████▋    | 241M/420M [00:03<00:02, 74.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  59%|█████▉    | 248M/420M [00:03<00:02, 72.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  61%|██████    | 255M/420M [00:03<00:02, 72.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  62%|██████▏   | 262M/420M [00:03<00:02, 73.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  64%|██████▍   | 269M/420M [00:03<00:02, 73.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  66%|██████▌   | 276M/420M [00:03<00:02, 73.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  67%|██████▋   | 283M/420M [00:04<00:01, 73.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  69%|██████▉   | 290M/420M [00:04<00:01, 73.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  71%|███████   | 297M/420M [00:04<00:01, 73.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  72%|███████▏  | 304M/420M [00:04<00:01, 74.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  74%|███████▍  | 311M/420M [00:04<00:01, 74.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  76%|███████▌  | 318M/420M [00:04<00:01, 74.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  77%|███████▋  | 325M/420M [00:04<00:01, 74.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  79%|███████▉  | 333M/420M [00:04<00:01, 74.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  81%|████████  | 340M/420M [00:04<00:01, 74.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  83%|████████▎ | 347M/420M [00:04<00:01, 74.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  84%|████████▍ | 354M/420M [00:05<00:00, 74.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  86%|████████▌ | 361M/420M [00:05<00:00, 74.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  88%|████████▊ | 368M/420M [00:05<00:00, 74.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  89%|████████▉ | 375M/420M [00:05<00:00, 74.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  91%|█████████ | 382M/420M [00:05<00:00, 74.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  93%|█████████▎| 389M/420M [00:05<00:00, 74.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  94%|█████████▍| 397M/420M [00:05<00:00, 74.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  96%|█████████▌| 404M/420M [00:05<00:00, 74.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  98%|█████████▊| 411M/420M [00:05<00:00, 74.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|█████████▉| 418M/420M [00:05<00:00, 74.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 420M/420M [00:05<00:00, 74.1MB/s]\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34mUsing XLA device\u001b[0m\n",
      "\u001b[34mUsing XLA device\u001b[0m\n",
      "\u001b[34m***** Running training *****\u001b[0m\n",
      "\u001b[34m***** Running training *****\n",
      "  Num examples = 853\u001b[0m\n",
      "\u001b[34mNum examples = 853\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\u001b[0m\n",
      "\u001b[34mTotal train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 107\u001b[0m\n",
      "\u001b[34mNum Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 107\u001b[0m\n",
      "\u001b[34m0%|          | 0/107 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-06-04 07:58:15.264 algo-1:27 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-06-04 07:58:15.377 algo-1:27 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m1%|          | 1/107 [00:00<00:55,  1.90it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 2/107 [00:38<39:26, 22.54s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 3/107 [01:18<52:42, 30.41s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 4/107 [01:18<31:46, 18.51s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 5/107 [01:18<20:17, 11.93s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 6/107 [01:19<13:24,  7.97s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 7/107 [01:19<09:05,  5.45s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 8/107 [01:19<06:16,  3.81s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 9/107 [01:19<04:24,  2.70s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 10/107 [01:20<03:09,  1.95s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 11/107 [01:20<02:17,  1.44s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 12/107 [01:20<01:43,  1.09s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 13/107 [01:20<01:18,  1.19it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 14/107 [01:21<01:02,  1.50it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 15/107 [01:21<00:50,  1.83it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 16/107 [01:21<00:42,  2.13it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 17/107 [01:22<00:36,  2.44it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 18/107 [01:22<00:32,  2.71it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 19/107 [01:22<00:29,  2.95it/s]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 20/107 [01:22<00:28,  3.06it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 21/107 [01:23<00:26,  3.22it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 22/107 [01:23<00:25,  3.36it/s]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 23/107 [01:23<00:24,  3.46it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 24/107 [01:24<00:23,  3.53it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 25/107 [01:24<00:22,  3.58it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 26/107 [01:24<00:22,  3.61it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 27/107 [01:24<00:22,  3.63it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 28/107 [01:25<00:22,  3.55it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 29/107 [01:25<00:21,  3.61it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 30/107 [01:25<00:21,  3.63it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 31/107 [01:25<00:20,  3.65it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 32/107 [01:26<00:20,  3.65it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 33/107 [01:26<00:20,  3.67it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 34/107 [01:26<00:19,  3.67it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 35/107 [01:27<00:19,  3.68it/s]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 36/107 [01:27<00:19,  3.59it/s]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 37/107 [01:27<00:19,  3.62it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 38/107 [01:27<00:18,  3.65it/s]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 39/107 [01:28<00:18,  3.67it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 40/107 [01:28<00:18,  3.61it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 41/107 [01:28<00:18,  3.65it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 42/107 [01:28<00:17,  3.67it/s]\u001b[0m\n",
      "\u001b[34m40%|████      | 43/107 [01:29<00:17,  3.68it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 44/107 [01:29<00:17,  3.61it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 45/107 [01:29<00:17,  3.64it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 46/107 [01:30<00:16,  3.64it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 47/107 [01:30<00:16,  3.65it/s]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 48/107 [01:30<00:16,  3.65it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 49/107 [01:30<00:15,  3.68it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 50/107 [01:31<00:15,  3.69it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 51/107 [01:31<00:15,  3.69it/s]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 52/107 [01:31<00:15,  3.61it/s]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 53/107 [01:31<00:14,  3.64it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 54/107 [01:32<00:14,  3.65it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m51%|█████▏    | 55/107 [01:32<00:14,  3.66it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 56/107 [01:32<00:14,  3.64it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 57/107 [01:33<00:13,  3.67it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 58/107 [01:33<00:13,  3.69it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 59/107 [01:33<00:12,  3.70it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 60/107 [01:33<00:12,  3.63it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 61/107 [01:34<00:12,  3.66it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 62/107 [01:34<00:12,  3.67it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 63/107 [01:34<00:12,  3.66it/s]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 64/107 [01:34<00:11,  3.60it/s]\u001b[0m\n",
      "\u001b[34m61%|██████    | 65/107 [01:35<00:11,  3.64it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 66/107 [01:35<00:11,  3.64it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 67/107 [01:35<00:10,  3.67it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 68/107 [01:36<00:10,  3.59it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 69/107 [01:36<00:10,  3.63it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 70/107 [01:36<00:10,  3.64it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 71/107 [01:36<00:09,  3.67it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 72/107 [01:37<00:09,  3.61it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 73/107 [01:37<00:09,  3.64it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 74/107 [01:37<00:09,  3.66it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 75/107 [01:37<00:08,  3.67it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 76/107 [01:38<00:08,  3.61it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 77/107 [01:38<00:08,  3.64it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 78/107 [01:38<00:07,  3.67it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 79/107 [01:39<00:07,  3.68it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 80/107 [01:39<00:07,  3.69it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 81/107 [01:39<00:07,  3.69it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 82/107 [01:39<00:06,  3.69it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 83/107 [01:40<00:06,  3.69it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 84/107 [01:40<00:06,  3.67it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 85/107 [01:40<00:05,  3.67it/s]\u001b[0m\n",
      "\u001b[34m80%|████████  | 86/107 [01:40<00:05,  3.68it/s]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 87/107 [01:41<00:05,  3.68it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 88/107 [01:41<00:05,  3.69it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 89/107 [01:41<00:04,  3.71it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 90/107 [01:42<00:04,  3.71it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 91/107 [01:42<00:04,  3.70it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 92/107 [01:42<00:04,  3.65it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 93/107 [01:42<00:03,  3.69it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 94/107 [01:43<00:03,  3.70it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 95/107 [01:43<00:03,  3.69it/s]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 96/107 [01:43<00:02,  3.69it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 97/107 [01:43<00:02,  3.70it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 98/107 [01:44<00:02,  3.68it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 99/107 [01:44<00:02,  3.68it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 100/107 [01:44<00:01,  3.68it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 101/107 [01:45<00:01,  3.68it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 102/107 [01:45<00:01,  3.67it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 103/107 [02:25<00:49, 12.35s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 104/107 [02:26<00:26,  8.73s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 105/107 [02:26<00:12,  6.19s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 106/107 [02:26<00:04,  4.42s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 107/107 [02:26<00:00,  3.18s/it]\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 216\u001b[0m\n",
      "\u001b[34mNum examples = 216\n",
      "  Batch size = 8\u001b[0m\n",
      "\u001b[34mBatch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/27 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m7%|▋         | 2/27 [00:00<00:01, 18.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m15%|█▍        | 4/27 [00:00<00:02, 11.36it/s]#033[A\u001b[0m\n",
      "\u001b[34m22%|██▏       | 6/27 [00:00<00:02, 10.49it/s]#033[A\u001b[0m\n",
      "\u001b[34m30%|██▉       | 8/27 [00:00<00:01,  9.75it/s]#033[A\u001b[0m\n",
      "\u001b[34m37%|███▋      | 10/27 [00:00<00:01,  9.65it/s]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 12/27 [00:01<00:01,  9.44it/s]#033[A\u001b[0m\n",
      "\u001b[34m48%|████▊     | 13/27 [00:01<00:01,  9.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 14/27 [00:01<00:01,  9.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 15/27 [00:01<00:01,  9.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 16/27 [00:01<00:01,  9.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 17/27 [00:01<00:01,  9.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 18/27 [00:01<00:00,  9.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m70%|███████   | 19/27 [00:01<00:00,  9.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 20/27 [00:02<00:00,  9.33it/s]#033[A\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 21/27 [00:02<00:00,  9.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 22/27 [00:02<00:00,  9.39it/s]#033[A\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 23/27 [00:02<00:00,  9.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 24/27 [00:02<00:00,  9.42it/s]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 25/27 [00:02<00:00,  9.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 26/27 [00:02<00:00,  9.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 27/27 [00:02<00:00,  9.50it/s]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 2.5112102031707764, 'eval_accuracy': 0.3194444444444444, 'eval_runtime': 46.5581, 'eval_samples_per_second': 4.639, 'eval_steps_per_second': 0.58, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m100%|██████████| 107/107 [03:13<00:00,  3.18s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 27/27 [00:02<00:00,  9.50it/s]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to ./results/checkpoint-107\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to ./results/checkpoint-107\u001b[0m\n",
      "\u001b[34mConfiguration saved in ./results/checkpoint-107/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in ./results/checkpoint-107/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in ./results/checkpoint-107/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in ./results/checkpoint-107/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in ./results/checkpoint-107/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in ./results/checkpoint-107/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in ./results/checkpoint-107/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in ./results/checkpoint-107/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34mLoading best model from ./results/checkpoint-107 (score: 2.5112102031707764).\u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34mLoading best model from ./results/checkpoint-107 (score: 2.5112102031707764).\u001b[0m\n",
      "\u001b[34m{'train_runtime': 198.9869, 'train_samples_per_second': 4.287, 'train_steps_per_second': 0.538, 'train_loss': 2.855259975540304, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m100%|██████████| 107/107 [03:18<00:00,  3.18s/it]#015100%|██████████| 107/107 [03:18<00:00,  1.86s/it]\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 216\u001b[0m\n",
      "\u001b[34mNum examples = 216\n",
      "  Batch size = 8\u001b[0m\n",
      "\u001b[34mBatch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/27 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 2/27 [00:00<00:01, 18.80it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 4/27 [00:00<00:02, 11.34it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 6/27 [00:00<00:01, 10.52it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 8/27 [00:00<00:01,  9.88it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 10/27 [00:00<00:01,  9.78it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 12/27 [00:01<00:01,  9.45it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 13/27 [00:01<00:01,  9.48it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 14/27 [00:01<00:01,  9.48it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 15/27 [00:01<00:01,  9.50it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 16/27 [00:01<00:01,  9.51it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 17/27 [00:01<00:01,  9.56it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 18/27 [00:01<00:00,  9.58it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 19/27 [00:01<00:00,  9.52it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 20/27 [00:02<00:00,  9.52it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 21/27 [00:02<00:00,  9.52it/s]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 22/27 [00:02<00:00,  9.58it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 23/27 [00:02<00:00,  9.62it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 24/27 [00:02<00:00,  9.65it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 25/27 [00:02<00:00,  9.68it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 26/27 [00:02<00:00,  9.69it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 27/27 [00:02<00:00,  9.66it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 27/27 [00:02<00:00,  9.80it/s]\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m2023-06-04 08:01:39,641 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-06-04 08:01:39,642 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-06-04 08:01:39,642 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2023-06-04 08:01:52 Uploading - Uploading generated training model\n",
      "2023-06-04 08:02:53 Completed - Training job completed\n",
      "Training seconds: 624\n",
      "Billable seconds: 624\n"
     ]
    }
   ],
   "source": [
    "huggingface_estimator1.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0034119a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://agtimeseries/mme-hf-folder/model1/bert-model-2023-06-04-07-51-04-231/output/model.tar.gz'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_estimator1.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e37d0eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.huggingface.estimator.HuggingFace at 0x7f37f76bb760>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_estimator1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c27d32",
   "metadata": {},
   "source": [
    "# Estimator: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b2768e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters={'epochs': 1,                                    # number of training epochs\n",
    "                 'train_batch_size': 8,                         # batch size for training\n",
    "                 'eval_batch_size': 8,                          #batch size for testing\n",
    "                 \"model_id\" :'bert-base-uncased'                #pretrained model name from hf\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ac328b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "huggingface_estimator2 = HuggingFace(\n",
    "    entry_point          = 'script3.py',       # script code to run the model      \n",
    "    source_dir           = 'code/',\n",
    "    instance_type        = 'ml.p3.2xlarge',    # instances type used for the training job\n",
    "    instance_count       = 1,                  # the number of instances used for training\n",
    "    base_job_name        = \"bert-model\",       # the name of the training job     \n",
    "    role                 = role,               # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    transformers_version = '4.11.0',           # the transformers version used in the training job\n",
    "    pytorch_version      = '1.9.0',            # the pytorch_version version used in the training job\n",
    "    py_version           = 'py38',             # the python version used in the training job\n",
    "    compiler_config      = compiler_config,    # the compiler configuration used in the training job\n",
    "    hyperparameters      = hyperparameters,    # the hyperparameter used for running the training job\n",
    "    disable_profiler     = True,               # whether to disable the profiler during training used to gain maximum performance\n",
    "    debugger_hook_config = False,              # whether to enable the debugger hook during training used to gain maximum performance\n",
    "    output_path          = model_data_loc2,     # s3 location where the final fine-tuned model will be saved \n",
    "    code_location        = script_code_loc2     # s3 location where the estimator will push the script code\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cbc211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'training': training_data_loc, 'testing': testing_data_loc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ec14f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: bert-model-2023-06-04-08-12-01-845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "2023-06-04 08:12:02 Starting - Starting the training job...\n",
      "2023-06-04 08:12:28 Starting - Preparing the instances for training......\n",
      "2023-06-04 08:13:30 Downloading - Downloading input data...\n",
      "2023-06-04 08:13:50 Training - Downloading the training image..............................\n",
      "2023-06-04 08:18:51 Training - Training image download completed. Training in progress...\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-06-04 08:19:13,709 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-06-04 08:19:13,736 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-06-04 08:19:13,739 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-06-04 08:19:13,996 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_training_compiler_debug_mode\": false,\n",
      "        \"sagemaker_training_compiler_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"testing\": \"/opt/ml/input/data/testing\",\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 1,\n",
      "        \"eval_batch_size\": 8,\n",
      "        \"model_id\": \"bert-base-uncased\",\n",
      "        \"train_batch_size\": 8\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"testing\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"bert-model-2023-06-04-08-12-01-845\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://agtimeseries/mme-hf-folder/scriptcode2/bert-model-2023-06-04-08-12-01-845/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"script3\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"script3.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":1,\"eval_batch_size\":8,\"model_id\":\"bert-base-uncased\",\"train_batch_size\":8}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=script3.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_training_compiler_debug_mode\":false,\"sagemaker_training_compiler_enabled\":true}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"testing\",\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=script3\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://agtimeseries/mme-hf-folder/scriptcode2/bert-model-2023-06-04-08-12-01-845/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_training_compiler_debug_mode\":false,\"sagemaker_training_compiler_enabled\":true},\"channel_input_dirs\":{\"testing\":\"/opt/ml/input/data/testing\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":1,\"eval_batch_size\":8,\"model_id\":\"bert-base-uncased\",\"train_batch_size\":8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"bert-model-2023-06-04-08-12-01-845\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://agtimeseries/mme-hf-folder/scriptcode2/bert-model-2023-06-04-08-12-01-845/source/sourcedir.tar.gz\",\"module_name\":\"script3\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"script3.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"1\",\"--eval_batch_size\",\"8\",\"--model_id\",\"bert-base-uncased\",\"--train_batch_size\",\"8\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TESTING=/opt/ml/input/data/testing\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_HP_EVAL_BATCH_SIZE=8\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_ID=bert-base-uncased\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_BATCH_SIZE=8\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python script3.py --epochs 1 --eval_batch_size 8 --model_id bert-base-uncased --train_batch_size 8\u001b[0m\n",
      "\u001b[34m[2023-06-04 08:19:14.052 torch.__training_compiler__.TrainingCompilerConfig INFO] Found configuration for Training Compiler. Compiler will be configured during import of torch_xla.\u001b[0m\n",
      "\u001b[34m[2023-06-04 08:19:15.085 torch_xla.__training_compiler__.TrainingCompilerConfig INFO] Configuring SM Training Compiler...\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 28.0/28.0 [00:00<00:00, 39.8kB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/570 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 570/570 [00:00<00:00, 859kB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/226k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 226k/226k [00:00<00:00, 45.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/455k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 455k/455k [00:00<00:00, 12.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/420M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading:   2%|▏         | 6.59M/420M [00:00<00:06, 69.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   3%|▎         | 13.8M/420M [00:00<00:05, 73.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   5%|▌         | 21.2M/420M [00:00<00:05, 74.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   7%|▋         | 28.5M/420M [00:00<00:05, 75.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   9%|▊         | 35.9M/420M [00:00<00:05, 76.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  10%|█         | 43.1M/420M [00:00<00:05, 76.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  12%|█▏        | 50.5M/420M [00:00<00:05, 76.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  14%|█▍        | 57.8M/420M [00:00<00:04, 76.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  15%|█▌        | 65.1M/420M [00:00<00:04, 76.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  17%|█▋        | 72.3M/420M [00:01<00:04, 76.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  19%|█▉        | 79.7M/420M [00:01<00:04, 76.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  21%|██        | 87.0M/420M [00:01<00:04, 76.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  22%|██▏       | 94.4M/420M [00:01<00:04, 76.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  24%|██▍       | 102M/420M [00:01<00:04, 76.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  26%|██▌       | 109M/420M [00:01<00:04, 76.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  28%|██▊       | 116M/420M [00:01<00:04, 76.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  29%|██▉       | 124M/420M [00:01<00:04, 76.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  31%|███       | 131M/420M [00:01<00:03, 76.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  33%|███▎      | 138M/420M [00:01<00:03, 76.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  35%|███▍      | 146M/420M [00:02<00:03, 76.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  36%|███▋      | 153M/420M [00:02<00:03, 76.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  38%|███▊      | 160M/420M [00:02<00:03, 77.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  40%|███▉      | 168M/420M [00:02<00:03, 77.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  42%|████▏     | 175M/420M [00:02<00:03, 77.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  43%|████▎     | 183M/420M [00:02<00:03, 77.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  45%|████▌     | 190M/420M [00:02<00:03, 77.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  47%|████▋     | 197M/420M [00:02<00:03, 77.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  49%|████▉     | 205M/420M [00:02<00:02, 78.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  51%|█████     | 212M/420M [00:02<00:02, 77.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  52%|█████▏    | 220M/420M [00:03<00:02, 77.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  54%|█████▍    | 227M/420M [00:03<00:02, 77.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  56%|█████▌    | 235M/420M [00:03<00:02, 77.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  58%|█████▊    | 242M/420M [00:03<00:02, 77.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  59%|█████▉    | 249M/420M [00:03<00:02, 77.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  61%|██████    | 257M/420M [00:03<00:02, 77.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  63%|██████▎   | 264M/420M [00:03<00:02, 77.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  65%|██████▍   | 272M/420M [00:03<00:02, 77.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  66%|██████▋   | 279M/420M [00:03<00:01, 77.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  68%|██████▊   | 286M/420M [00:03<00:01, 77.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  70%|██████▉   | 294M/420M [00:04<00:01, 77.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  72%|███████▏  | 301M/420M [00:04<00:01, 77.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  73%|███████▎  | 308M/420M [00:04<00:01, 77.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  75%|███████▌  | 316M/420M [00:04<00:01, 77.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  77%|███████▋  | 323M/420M [00:04<00:01, 77.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  79%|███████▊  | 331M/420M [00:04<00:01, 77.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  80%|████████  | 338M/420M [00:04<00:01, 77.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  82%|████████▏ | 345M/420M [00:04<00:01, 76.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  84%|████████▍ | 353M/420M [00:04<00:00, 77.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  86%|████████▌ | 360M/420M [00:04<00:00, 77.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  87%|████████▋ | 367M/420M [00:05<00:00, 76.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  89%|████████▉ | 375M/420M [00:05<00:00, 76.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  91%|█████████ | 382M/420M [00:05<00:00, 76.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  93%|█████████▎| 390M/420M [00:05<00:00, 77.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  94%|█████████▍| 397M/420M [00:05<00:00, 77.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  96%|█████████▌| 404M/420M [00:05<00:00, 77.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  98%|█████████▊| 412M/420M [00:05<00:00, 77.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|█████████▉| 419M/420M [00:05<00:00, 77.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 420M/420M [00:05<00:00, 76.9MB/s]\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mUsing XLA device\u001b[0m\n",
      "\u001b[34mUsing XLA device\u001b[0m\n",
      "\u001b[34m***** Running training *****\u001b[0m\n",
      "\u001b[34m***** Running training *****\n",
      "  Num examples = 853\u001b[0m\n",
      "\u001b[34mNum examples = 853\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\u001b[0m\n",
      "\u001b[34mTotal train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 107\u001b[0m\n",
      "\u001b[34mNum Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 107\u001b[0m\n",
      "\u001b[34m0%|          | 0/107 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-06-04 08:19:28.524 algo-1:27 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-06-04 08:19:28.633 algo-1:27 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m1%|          | 1/107 [00:00<00:54,  1.96it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 2/107 [00:38<39:18, 22.46s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 3/107 [01:17<52:24, 30.24s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 4/107 [01:18<31:36, 18.42s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 5/107 [01:18<20:10, 11.87s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 6/107 [01:18<13:20,  7.93s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 7/107 [01:18<09:02,  5.42s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 8/107 [01:19<06:15,  3.79s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 9/107 [01:19<04:23,  2.69s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 10/107 [01:19<03:07,  1.94s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 11/107 [01:20<02:17,  1.43s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 12/107 [01:20<01:42,  1.08s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 13/107 [01:20<01:18,  1.20it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 14/107 [01:20<01:01,  1.51it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 15/107 [01:21<00:49,  1.84it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 16/107 [01:21<00:42,  2.16it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 17/107 [01:21<00:36,  2.49it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 18/107 [01:21<00:32,  2.76it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 19/107 [01:22<00:29,  3.01it/s]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 20/107 [01:22<00:27,  3.20it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 21/107 [01:22<00:25,  3.36it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 22/107 [01:22<00:24,  3.48it/s]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 23/107 [01:23<00:23,  3.57it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 24/107 [01:23<00:23,  3.54it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 25/107 [01:23<00:22,  3.62it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 26/107 [01:24<00:22,  3.66it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 27/107 [01:24<00:21,  3.71it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 28/107 [01:24<00:21,  3.73it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 29/107 [01:24<00:20,  3.75it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 30/107 [01:25<00:20,  3.75it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 31/107 [01:25<00:20,  3.76it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 32/107 [01:25<00:19,  3.77it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 33/107 [01:25<00:19,  3.76it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 34/107 [01:26<00:19,  3.75it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 35/107 [01:26<00:19,  3.76it/s]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 36/107 [01:26<00:18,  3.75it/s]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 37/107 [01:26<00:18,  3.73it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 38/107 [01:27<00:18,  3.73it/s]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 39/107 [01:27<00:18,  3.74it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 40/107 [01:27<00:18,  3.66it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 41/107 [01:28<00:17,  3.69it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 42/107 [01:28<00:17,  3.71it/s]\u001b[0m\n",
      "\u001b[34m40%|████      | 43/107 [01:28<00:17,  3.70it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 44/107 [01:28<00:17,  3.62it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 45/107 [01:29<00:17,  3.64it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 46/107 [01:29<00:16,  3.66it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 47/107 [01:29<00:16,  3.70it/s]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 48/107 [01:29<00:16,  3.63it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 49/107 [01:30<00:15,  3.64it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 50/107 [01:30<00:15,  3.64it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 51/107 [01:30<00:15,  3.66it/s]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 52/107 [01:31<00:15,  3.65it/s]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 53/107 [01:31<00:14,  3.66it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 54/107 [01:31<00:14,  3.68it/s]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 55/107 [01:31<00:14,  3.70it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 56/107 [01:32<00:14,  3.62it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 57/107 [01:32<00:13,  3.66it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 58/107 [01:32<00:13,  3.68it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 59/107 [01:32<00:13,  3.69it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 60/107 [01:33<00:13,  3.59it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 61/107 [01:33<00:12,  3.63it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 62/107 [01:33<00:12,  3.64it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 63/107 [01:34<00:12,  3.65it/s]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 64/107 [01:34<00:12,  3.51it/s]\u001b[0m\n",
      "\u001b[34m61%|██████    | 65/107 [01:34<00:11,  3.54it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 66/107 [01:34<00:11,  3.58it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 67/107 [01:35<00:11,  3.63it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 68/107 [01:35<00:10,  3.67it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 69/107 [01:35<00:10,  3.69it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 70/107 [01:35<00:09,  3.71it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 71/107 [01:36<00:09,  3.72it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 72/107 [01:36<00:09,  3.63it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 73/107 [01:36<00:09,  3.66it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 74/107 [01:37<00:08,  3.67it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 75/107 [01:37<00:08,  3.70it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 76/107 [01:37<00:08,  3.71it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 77/107 [01:37<00:08,  3.70it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 78/107 [01:38<00:07,  3.71it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 79/107 [01:38<00:07,  3.72it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 80/107 [01:38<00:07,  3.64it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 81/107 [01:38<00:07,  3.66it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 82/107 [01:39<00:06,  3.67it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 83/107 [01:39<00:06,  3.70it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 84/107 [01:39<00:06,  3.64it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 85/107 [01:40<00:05,  3.69it/s]\u001b[0m\n",
      "\u001b[34m80%|████████  | 86/107 [01:40<00:05,  3.70it/s]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 87/107 [01:40<00:05,  3.73it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 88/107 [01:40<00:05,  3.70it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 89/107 [01:41<00:04,  3.73it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 90/107 [01:41<00:04,  3.75it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 91/107 [01:41<00:04,  3.77it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 92/107 [01:41<00:03,  3.75it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 93/107 [01:42<00:03,  3.76it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 94/107 [01:42<00:03,  3.75it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 95/107 [01:42<00:03,  3.75it/s]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 96/107 [01:43<00:02,  3.75it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 97/107 [01:43<00:02,  3.76it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 98/107 [01:43<00:02,  3.77it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 99/107 [01:43<00:02,  3.77it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 100/107 [01:44<00:01,  3.77it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 101/107 [01:44<00:01,  3.78it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 102/107 [01:44<00:01,  3.77it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 103/107 [02:24<00:48, 12.12s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 104/107 [02:24<00:25,  8.56s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 105/107 [02:24<00:12,  6.07s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 106/107 [02:25<00:04,  4.33s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 107/107 [02:25<00:00,  3.12s/it]\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34mNum examples = 216\n",
      "  Batch size = 8\u001b[0m\n",
      "\u001b[34mNum examples = 216\n",
      "  Batch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/27 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m7%|▋         | 2/27 [00:00<00:01, 19.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m15%|█▍        | 4/27 [00:00<00:02, 11.36it/s]#033[A\u001b[0m\n",
      "\u001b[34m22%|██▏       | 6/27 [00:00<00:01, 10.57it/s]#033[A\u001b[0m\n",
      "\u001b[34m30%|██▉       | 8/27 [00:00<00:01,  9.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m37%|███▋      | 10/27 [00:00<00:01,  9.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 12/27 [00:01<00:01,  9.61it/s]#033[A\u001b[0m\n",
      "\u001b[34m48%|████▊     | 13/27 [00:01<00:01,  9.59it/s]#033[A\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 14/27 [00:01<00:01,  9.57it/s]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 15/27 [00:01<00:01,  9.63it/s]#033[A\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 16/27 [00:01<00:01,  9.62it/s]#033[A\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 17/27 [00:01<00:01,  9.66it/s]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 18/27 [00:01<00:00,  9.68it/s]#033[A\u001b[0m\n",
      "\u001b[34m70%|███████   | 19/27 [00:01<00:00,  9.68it/s]#033[A\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 20/27 [00:02<00:00,  9.62it/s]#033[A\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 21/27 [00:02<00:00,  9.65it/s]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 22/27 [00:02<00:00,  9.62it/s]#033[A\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 23/27 [00:02<00:00,  9.67it/s]#033[A\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 24/27 [00:02<00:00,  9.66it/s]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 25/27 [00:02<00:00,  9.68it/s]#033[A\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 26/27 [00:02<00:00,  9.72it/s]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 27/27 [00:02<00:00,  9.72it/s]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 2.4068143367767334, 'eval_accuracy': 0.38425925925925924, 'eval_runtime': 46.1031, 'eval_samples_per_second': 4.685, 'eval_steps_per_second': 0.586, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m100%|██████████| 107/107 [03:11<00:00,  3.12s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 27/27 [00:02<00:00,  9.72it/s]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to ./results/checkpoint-107\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to ./results/checkpoint-107\u001b[0m\n",
      "\u001b[34mConfiguration saved in ./results/checkpoint-107/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in ./results/checkpoint-107/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in ./results/checkpoint-107/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in ./results/checkpoint-107/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in ./results/checkpoint-107/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in ./results/checkpoint-107/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in ./results/checkpoint-107/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in ./results/checkpoint-107/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34mLoading best model from ./results/checkpoint-107 (score: 2.4068143367767334).\u001b[0m\n",
      "\u001b[34mLoading best model from ./results/checkpoint-107 (score: 2.4068143367767334).\u001b[0m\n",
      "\u001b[34m{'train_runtime': 197.4037, 'train_samples_per_second': 4.321, 'train_steps_per_second': 0.542, 'train_loss': 2.77031358380184, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m100%|██████████| 107/107 [03:17<00:00,  3.12s/it]#015100%|██████████| 107/107 [03:17<00:00,  1.84s/it]\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 216\u001b[0m\n",
      "\u001b[34mNum examples = 216\n",
      "  Batch size = 8\u001b[0m\n",
      "\u001b[34mBatch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/27 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 2/27 [00:00<00:01, 19.02it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 4/27 [00:00<00:01, 11.63it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m22%|██▏       | 6/27 [00:00<00:02, 10.36it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 8/27 [00:00<00:01,  9.87it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 10/27 [00:00<00:01,  9.87it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 12/27 [00:01<00:01,  9.75it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 14/27 [00:01<00:01,  9.79it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 15/27 [00:01<00:01,  9.76it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 16/27 [00:01<00:01,  9.74it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 17/27 [00:01<00:01,  9.75it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 18/27 [00:01<00:00,  9.77it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 19/27 [00:01<00:00,  9.74it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 20/27 [00:01<00:00,  9.76it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 21/27 [00:02<00:00,  9.70it/s]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 22/27 [00:02<00:00,  9.70it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 23/27 [00:02<00:00,  9.74it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 24/27 [00:02<00:00,  9.71it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 25/27 [00:02<00:00,  9.73it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 26/27 [00:02<00:00,  9.70it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 27/27 [00:02<00:00,  9.74it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 27/27 [00:02<00:00,  9.95it/s]\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m2023-06-04 08:22:51,267 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-06-04 08:22:51,268 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-06-04 08:22:51,268 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-06-04 08:23:02 Uploading - Uploading generated training model\n",
      "2023-06-04 08:24:08 Completed - Training job completed\n",
      "Training seconds: 639\n",
      "Billable seconds: 639\n"
     ]
    }
   ],
   "source": [
    "huggingface_estimator2.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd90e7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec118c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9273d1c6",
   "metadata": {},
   "source": [
    "# Estimator: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8edf544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters={'epochs': 1,                                    # number of training epochs\n",
    "                 'train_batch_size': 8,                         # batch size for training\n",
    "                 'eval_batch_size': 8,                          #batch size for testing\n",
    "                 \"model_id\" :'bert-base-uncased'                #pretrained model name from hf\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1c333b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "huggingface_estimator3 = HuggingFace(\n",
    "    entry_point          = 'script3.py',       # script code to run the model      \n",
    "    source_dir           = 'code/',\n",
    "    instance_type        = 'ml.p3.2xlarge',    # instances type used for the training job\n",
    "    instance_count       = 1,                  # the number of instances used for training\n",
    "    base_job_name        = \"bert-model\",       # the name of the training job     \n",
    "    role                 = role,               # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    transformers_version = '4.11.0',           # the transformers version used in the training job\n",
    "    pytorch_version      = '1.9.0',            # the pytorch_version version used in the training job\n",
    "    py_version           = 'py38',             # the python version used in the training job\n",
    "    compiler_config      = compiler_config,    # the compiler configuration used in the training job\n",
    "    hyperparameters      = hyperparameters,    # the hyperparameter used for running the training job\n",
    "    disable_profiler     = True,               # whether to disable the profiler during training used to gain maximum performance\n",
    "    debugger_hook_config = False,              # whether to enable the debugger hook during training used to gain maximum performance\n",
    "    output_path          = model_data_loc3,     # s3 location where the final fine-tuned model will be saved \n",
    "    code_location        = script_code_loc3     # s3 location where the estimator will push the script code\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dec2f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'training': training_data_loc, 'testing': testing_data_loc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "979acc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: bert-model-2023-06-04-08-24-23-178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-04 08:24:23 Starting - Starting the training job...\n",
      "2023-06-04 08:24:49 Starting - Preparing the instances for training......\n",
      "2023-06-04 08:25:52 Downloading - Downloading input data...\n",
      "2023-06-04 08:26:12 Training - Downloading the training image..............................\n",
      "2023-06-04 08:31:24 Training - Training image download completed. Training in progress.....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-06-04 08:31:51,286 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-06-04 08:31:51,313 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-06-04 08:31:51,315 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-06-04 08:31:51,562 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_training_compiler_debug_mode\": false,\n",
      "        \"sagemaker_training_compiler_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"testing\": \"/opt/ml/input/data/testing\",\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 1,\n",
      "        \"eval_batch_size\": 8,\n",
      "        \"model_id\": \"bert-base-uncased\",\n",
      "        \"train_batch_size\": 8\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"testing\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"bert-model-2023-06-04-08-24-23-178\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://agtimeseries/mme-hf-folder/scriptcode3/bert-model-2023-06-04-08-24-23-178/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"script3\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"script3.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":1,\"eval_batch_size\":8,\"model_id\":\"bert-base-uncased\",\"train_batch_size\":8}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=script3.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_training_compiler_debug_mode\":false,\"sagemaker_training_compiler_enabled\":true}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"testing\",\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=script3\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://agtimeseries/mme-hf-folder/scriptcode3/bert-model-2023-06-04-08-24-23-178/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_training_compiler_debug_mode\":false,\"sagemaker_training_compiler_enabled\":true},\"channel_input_dirs\":{\"testing\":\"/opt/ml/input/data/testing\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":1,\"eval_batch_size\":8,\"model_id\":\"bert-base-uncased\",\"train_batch_size\":8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"bert-model-2023-06-04-08-24-23-178\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://agtimeseries/mme-hf-folder/scriptcode3/bert-model-2023-06-04-08-24-23-178/source/sourcedir.tar.gz\",\"module_name\":\"script3\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"script3.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"1\",\"--eval_batch_size\",\"8\",\"--model_id\",\"bert-base-uncased\",\"--train_batch_size\",\"8\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TESTING=/opt/ml/input/data/testing\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_HP_EVAL_BATCH_SIZE=8\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_ID=bert-base-uncased\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_BATCH_SIZE=8\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python script3.py --epochs 1 --eval_batch_size 8 --model_id bert-base-uncased --train_batch_size 8\u001b[0m\n",
      "\u001b[34m[2023-06-04 08:31:51.619 torch.__training_compiler__.TrainingCompilerConfig INFO] Found configuration for Training Compiler. Compiler will be configured during import of torch_xla.\u001b[0m\n",
      "\u001b[34m[2023-06-04 08:31:52.665 torch_xla.__training_compiler__.TrainingCompilerConfig INFO] Configuring SM Training Compiler...\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 28.0/28.0 [00:00<00:00, 35.1kB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/570 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 570/570 [00:00<00:00, 794kB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/226k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 226k/226k [00:00<00:00, 47.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/455k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 455k/455k [00:00<00:00, 12.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/420M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading:   2%|▏         | 6.56M/420M [00:00<00:06, 68.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   3%|▎         | 13.8M/420M [00:00<00:05, 72.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   5%|▌         | 21.0M/420M [00:00<00:05, 74.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   7%|▋         | 28.4M/420M [00:00<00:05, 75.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   8%|▊         | 35.6M/420M [00:00<00:05, 75.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  10%|█         | 42.9M/420M [00:00<00:05, 75.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  12%|█▏        | 50.1M/420M [00:00<00:05, 75.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  14%|█▎        | 57.3M/420M [00:00<00:05, 75.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  15%|█▌        | 64.4M/420M [00:00<00:04, 75.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  17%|█▋        | 71.7M/420M [00:01<00:04, 75.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  19%|█▉        | 79.0M/420M [00:01<00:04, 75.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  21%|██        | 86.2M/420M [00:01<00:04, 75.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  22%|██▏       | 93.5M/420M [00:01<00:04, 75.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  24%|██▍       | 101M/420M [00:01<00:04, 75.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  26%|██▌       | 108M/420M [00:01<00:04, 75.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  27%|██▋       | 115M/420M [00:01<00:04, 76.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  29%|██▉       | 123M/420M [00:01<00:04, 76.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  31%|███       | 130M/420M [00:01<00:03, 76.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  33%|███▎      | 137M/420M [00:01<00:03, 76.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  34%|███▍      | 145M/420M [00:02<00:03, 76.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  36%|███▌      | 152M/420M [00:02<00:03, 76.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  38%|███▊      | 159M/420M [00:02<00:03, 76.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  40%|███▉      | 166M/420M [00:02<00:03, 76.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  41%|████▏     | 174M/420M [00:02<00:03, 76.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  43%|████▎     | 181M/420M [00:02<00:03, 76.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  45%|████▍     | 188M/420M [00:02<00:03, 76.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  47%|████▋     | 196M/420M [00:02<00:03, 76.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  48%|████▊     | 203M/420M [00:02<00:02, 76.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  50%|█████     | 210M/420M [00:02<00:02, 76.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  52%|█████▏    | 218M/420M [00:03<00:02, 76.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  54%|█████▎    | 225M/420M [00:03<00:02, 76.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  55%|█████▌    | 232M/420M [00:03<00:02, 76.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  57%|█████▋    | 239M/420M [00:03<00:02, 76.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  59%|█████▊    | 247M/420M [00:03<00:02, 76.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  60%|██████    | 254M/420M [00:03<00:02, 76.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  62%|██████▏   | 261M/420M [00:03<00:02, 75.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  64%|██████▍   | 269M/420M [00:03<00:02, 76.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  66%|██████▌   | 276M/420M [00:03<00:01, 76.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  67%|██████▋   | 283M/420M [00:03<00:01, 76.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  69%|██████▉   | 290M/420M [00:04<00:01, 76.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  71%|███████   | 298M/420M [00:04<00:01, 76.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  73%|███████▎  | 305M/420M [00:04<00:01, 76.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  74%|███████▍  | 312M/420M [00:04<00:01, 76.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  76%|███████▌  | 319M/420M [00:04<00:01, 76.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  78%|███████▊  | 327M/420M [00:04<00:01, 76.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  80%|███████▉  | 334M/420M [00:04<00:01, 76.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  81%|████████  | 341M/420M [00:04<00:01, 76.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  83%|████████▎ | 349M/420M [00:04<00:00, 76.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  85%|████████▍ | 356M/420M [00:04<00:00, 76.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  86%|████████▋ | 363M/420M [00:05<00:00, 76.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  88%|████████▊ | 370M/420M [00:05<00:00, 76.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  90%|████████▉ | 378M/420M [00:05<00:00, 76.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  92%|█████████▏| 385M/420M [00:05<00:00, 76.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  93%|█████████▎| 392M/420M [00:05<00:00, 76.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  95%|█████████▌| 400M/420M [00:05<00:00, 76.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  97%|█████████▋| 407M/420M [00:05<00:00, 76.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  99%|█████████▊| 414M/420M [00:05<00:00, 76.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 420M/420M [00:05<00:00, 76.0MB/s]\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mUsing XLA device\u001b[0m\n",
      "\u001b[34mUsing XLA device\u001b[0m\n",
      "\u001b[34m***** Running training *****\u001b[0m\n",
      "\u001b[34mNum examples = 853\u001b[0m\n",
      "\u001b[34m***** Running training *****\n",
      "  Num examples = 853\u001b[0m\n",
      "\u001b[34mNum Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\u001b[0m\n",
      "\u001b[34mNum Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\u001b[0m\n",
      "\u001b[34mTotal optimization steps = 107\u001b[0m\n",
      "\u001b[34mTotal optimization steps = 107\u001b[0m\n",
      "\u001b[34m0%|          | 0/107 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-06-04 08:32:06.287 algo-1:27 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-06-04 08:32:06.401 algo-1:27 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m1%|          | 1/107 [00:00<00:56,  1.86it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 2/107 [00:38<39:42, 22.69s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 3/107 [01:18<52:57, 30.56s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 4/107 [01:18<31:56, 18.60s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 5/107 [01:19<20:23, 11.99s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 6/107 [01:19<13:28,  8.01s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 7/107 [01:19<09:07,  5.48s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 8/107 [01:20<06:18,  3.82s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 9/107 [01:20<04:25,  2.71s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 10/107 [01:20<03:09,  1.96s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 11/107 [01:20<02:18,  1.44s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 12/107 [01:21<01:43,  1.09s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 13/107 [01:21<01:19,  1.19it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 14/107 [01:21<01:02,  1.50it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 15/107 [01:21<00:50,  1.83it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 16/107 [01:22<00:42,  2.15it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 17/107 [01:22<00:36,  2.45it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 18/107 [01:22<00:32,  2.74it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 19/107 [01:23<00:29,  2.98it/s]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 20/107 [01:23<00:27,  3.16it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 21/107 [01:23<00:25,  3.31it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 22/107 [01:23<00:24,  3.42it/s]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 23/107 [01:24<00:24,  3.48it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 24/107 [01:24<00:23,  3.54it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 25/107 [01:24<00:22,  3.59it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 26/107 [01:24<00:22,  3.62it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 27/107 [01:25<00:21,  3.64it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 28/107 [01:25<00:21,  3.59it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 29/107 [01:25<00:21,  3.63it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 30/107 [01:25<00:21,  3.64it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 31/107 [01:26<00:20,  3.65it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 32/107 [01:26<00:20,  3.59it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 33/107 [01:26<00:20,  3.64it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 34/107 [01:27<00:19,  3.66it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 35/107 [01:27<00:19,  3.68it/s]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 36/107 [01:27<00:19,  3.68it/s]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 37/107 [01:27<00:18,  3.70it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 38/107 [01:28<00:18,  3.71it/s]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 39/107 [01:28<00:18,  3.70it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 40/107 [01:28<00:18,  3.60it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 41/107 [01:29<00:18,  3.62it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 42/107 [01:29<00:17,  3.65it/s]\u001b[0m\n",
      "\u001b[34m40%|████      | 43/107 [01:29<00:17,  3.67it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 44/107 [01:29<00:17,  3.59it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 45/107 [01:30<00:17,  3.62it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 46/107 [01:30<00:16,  3.62it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 47/107 [01:30<00:16,  3.65it/s]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 48/107 [01:30<00:16,  3.65it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 49/107 [01:31<00:15,  3.67it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 50/107 [01:31<00:15,  3.68it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 51/107 [01:31<00:15,  3.68it/s]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 52/107 [01:32<00:14,  3.68it/s]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 53/107 [01:32<00:14,  3.70it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 54/107 [01:32<00:14,  3.69it/s]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 55/107 [01:32<00:14,  3.70it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 56/107 [01:33<00:13,  3.66it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 57/107 [01:33<00:13,  3.69it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 58/107 [01:33<00:13,  3.71it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 59/107 [01:33<00:12,  3.71it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 60/107 [01:34<00:12,  3.68it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 61/107 [01:34<00:12,  3.68it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 62/107 [01:34<00:12,  3.68it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 63/107 [01:34<00:12,  3.66it/s]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 64/107 [01:35<00:12,  3.56it/s]\u001b[0m\n",
      "\u001b[34m61%|██████    | 65/107 [01:35<00:11,  3.62it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 66/107 [01:35<00:11,  3.64it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 67/107 [01:36<00:10,  3.65it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 68/107 [01:36<00:10,  3.57it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 69/107 [01:36<00:10,  3.61it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 70/107 [01:36<00:10,  3.52it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 71/107 [01:37<00:10,  3.56it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 72/107 [01:37<00:09,  3.60it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 73/107 [01:37<00:09,  3.62it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 74/107 [01:38<00:09,  3.63it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 75/107 [01:38<00:08,  3.65it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 76/107 [01:38<00:08,  3.66it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 77/107 [01:38<00:08,  3.69it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 78/107 [01:39<00:07,  3.71it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 79/107 [01:39<00:07,  3.71it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 80/107 [01:39<00:07,  3.64it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 81/107 [01:39<00:07,  3.67it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 82/107 [01:40<00:06,  3.70it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 83/107 [01:40<00:06,  3.72it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 84/107 [01:40<00:06,  3.72it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 85/107 [01:41<00:05,  3.74it/s]\u001b[0m\n",
      "\u001b[34m80%|████████  | 86/107 [01:41<00:05,  3.71it/s]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 87/107 [01:41<00:05,  3.72it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 88/107 [01:41<00:05,  3.62it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 89/107 [01:42<00:04,  3.66it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 90/107 [01:42<00:04,  3.67it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 91/107 [01:42<00:04,  3.69it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 92/107 [01:42<00:04,  3.71it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 93/107 [01:43<00:03,  3.72it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 94/107 [01:43<00:03,  3.73it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 95/107 [01:43<00:03,  3.73it/s]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 96/107 [01:43<00:02,  3.73it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 97/107 [01:44<00:02,  3.72it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 98/107 [01:44<00:02,  3.74it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 99/107 [01:44<00:02,  3.74it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 100/107 [01:45<00:01,  3.72it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 101/107 [01:45<00:01,  3.74it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 102/107 [01:45<00:01,  3.74it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 103/107 [02:24<00:47, 11.93s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 104/107 [02:25<00:25,  8.43s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 105/107 [02:25<00:11,  5.99s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 106/107 [02:25<00:04,  4.27s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 107/107 [02:25<00:00,  3.08s/it]\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 216\u001b[0m\n",
      "\u001b[34mNum examples = 216\n",
      "  Batch size = 8\u001b[0m\n",
      "\u001b[34mBatch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/27 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m7%|▋         | 2/27 [00:00<00:01, 18.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m15%|█▍        | 4/27 [00:00<00:01, 11.68it/s]#033[A\u001b[0m\n",
      "\u001b[34m22%|██▏       | 6/27 [00:00<00:01, 10.60it/s]#033[A\u001b[0m\n",
      "\u001b[34m30%|██▉       | 8/27 [00:00<00:01,  9.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m37%|███▋      | 10/27 [00:00<00:01,  9.82it/s]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 12/27 [00:01<00:01,  9.62it/s]#033[A\u001b[0m\n",
      "\u001b[34m48%|████▊     | 13/27 [00:01<00:01,  9.62it/s]#033[A\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 14/27 [00:01<00:01,  9.58it/s]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 15/27 [00:01<00:01,  9.60it/s]#033[A\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 16/27 [00:01<00:01,  9.57it/s]#033[A\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 17/27 [00:01<00:01,  9.58it/s]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 18/27 [00:01<00:00,  9.58it/s]#033[A\u001b[0m\n",
      "\u001b[34m70%|███████   | 19/27 [00:01<00:00,  9.56it/s]#033[A\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 20/27 [00:02<00:00,  9.58it/s]#033[A\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 21/27 [00:02<00:00,  9.58it/s]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 22/27 [00:02<00:00,  9.54it/s]#033[A\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 23/27 [00:02<00:00,  9.55it/s]#033[A\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 24/27 [00:02<00:00,  9.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 25/27 [00:02<00:00,  9.48it/s]#033[A\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 26/27 [00:02<00:00,  9.52it/s]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 27/27 [00:02<00:00,  9.57it/s]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 2.345978260040283, 'eval_accuracy': 0.37962962962962965, 'eval_runtime': 45.9009, 'eval_samples_per_second': 4.706, 'eval_steps_per_second': 0.588, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m100%|██████████| 107/107 [03:11<00:00,  3.08s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 27/27 [00:02<00:00,  9.57it/s]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to ./results/checkpoint-107\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to ./results/checkpoint-107\u001b[0m\n",
      "\u001b[34mConfiguration saved in ./results/checkpoint-107/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in ./results/checkpoint-107/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in ./results/checkpoint-107/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in ./results/checkpoint-107/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in ./results/checkpoint-107/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in ./results/checkpoint-107/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in ./results/checkpoint-107/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in ./results/checkpoint-107/special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34mLoading best model from ./results/checkpoint-107 (score: 2.345978260040283).\u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34mLoading best model from ./results/checkpoint-107 (score: 2.345978260040283).\u001b[0m\n",
      "\u001b[34m{'train_runtime': 197.1193, 'train_samples_per_second': 4.327, 'train_steps_per_second': 0.543, 'train_loss': 2.7093560049466996, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m100%|██████████| 107/107 [03:17<00:00,  3.08s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 107/107 [03:17<00:00,  1.84s/it]\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 216\u001b[0m\n",
      "\u001b[34mNum examples = 216\n",
      "  Batch size = 8\u001b[0m\n",
      "\u001b[34mBatch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/27 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 2/27 [00:00<00:01, 19.36it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 4/27 [00:00<00:02, 11.49it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 6/27 [00:00<00:02, 10.48it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 8/27 [00:00<00:01,  9.82it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 10/27 [00:00<00:01,  9.75it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 12/27 [00:01<00:01,  9.52it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 13/27 [00:01<00:01,  9.51it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 14/27 [00:01<00:01,  9.50it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 15/27 [00:01<00:01,  9.48it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 16/27 [00:01<00:01,  9.37it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 17/27 [00:01<00:01,  9.40it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 18/27 [00:01<00:00,  9.45it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 19/27 [00:01<00:00,  9.50it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 20/27 [00:02<00:00,  9.51it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 21/27 [00:02<00:00,  9.53it/s]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 22/27 [00:02<00:00,  9.56it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 23/27 [00:02<00:00,  9.60it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 24/27 [00:02<00:00,  9.57it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 25/27 [00:02<00:00,  9.61it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 26/27 [00:02<00:00,  9.58it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 27/27 [00:02<00:00,  9.56it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 27/27 [00:02<00:00,  9.76it/s]\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m2023-06-04 08:35:28,632 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-06-04 08:35:28,632 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-06-04 08:35:28,632 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-06-04 08:35:40 Uploading - Uploading generated training model\n",
      "2023-06-04 08:36:45 Completed - Training job completed\n",
      "Training seconds: 653\n",
      "Billable seconds: 653\n"
     ]
    }
   ],
   "source": [
    "huggingface_estimator3.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b2c2c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb90d824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6095f8df",
   "metadata": {},
   "source": [
    "# Endpoint Name and update the location of both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "62f5a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "DATA_PREFIX = \"DEMO_HF_MME_Ver1\"\n",
    "CUR = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "MULTI_MODEL_ARTIFACTS = \"multi_model_artifacts\"+ \"-\" + CUR\n",
    "\n",
    "CUR = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "ENDPOINT_NAME = \"mme-hf-POC-V1\" + \"-\" + CUR\n",
    "\n",
    "MODEL_NAME = ENDPOINT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "59ff6bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mme-hf-POC-V1-2023-06-05-13-44-06'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENDPOINT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a5401109",
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodels_path = f\"s3://{bucket_name}/{DATA_PREFIX}/{MULTI_MODEL_ARTIFACTS}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "edbad010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://agtimeseries/DEMO_HF_MME_Ver1/multi_model_artifacts-2023-06-05-10-14-02/'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multimodels_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e2e393df",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators=[]\n",
    "estimators.append(huggingface_estimator1)\n",
    "estimators.append(huggingface_estimator2)\n",
    "estimators.append(huggingface_estimator3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5bdf5181",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a1751776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the model from the base location to the new location where both of them will be saved\n",
    "for est in estimators:\n",
    "    artifact_path = est.latest_training_job.describe()[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "    model_name = artifact_path.split(\"/\")[-4] + \".tar.gz\"\n",
    "    prefix=multimodels_path.split(bucket_name)[1][1:]\n",
    "    model_path=prefix+model_name\n",
    "    s3.Object(bucket_name,model_path).copy_from(CopySource=artifact_path.split(\"//\")[1])   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c752219",
   "metadata": {},
   "source": [
    "# Create Model, Endpoint Config, Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b65a88f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://agtimeseries/DEMO_HF_MME_Ver1/multi_model_artifacts-2023-06-05-10-14-02/'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multimodels_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "60e3ac9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:us-east-2:831536787935:model/mme-hf-POC-V1-2023-06-05-13-44-06\n"
     ]
    }
   ],
   "source": [
    "sm_client = boto3.client(\"sagemaker\")\n",
    "# image_uri will depend on the region\n",
    "image_uri = \"763104351884.dkr.ecr.us-east-2.amazonaws.com/huggingface-pytorch-inference:1.9.0-transformers4.11.0-cpu-py38-ubuntu20.04\"\n",
    "primary_container = {\n",
    "    'Image': image_uri,\n",
    "    'Mode': 'MultiModel',\n",
    "    'ModelDataUrl': multimodels_path,\n",
    "    'Environment': {\n",
    "        'SAGEMAKER_PROGRAM': 'inference.py',\n",
    "        'SAGEMAKER_REGION': region,\n",
    "        'SAGEMAKER_SUBMIT_DIRECTORY': multimodels_path\n",
    "    }\n",
    "}\n",
    "\n",
    "create_model_response = sm_client.create_model(ModelName = ENDPOINT_NAME,\n",
    "                                              ExecutionRoleArn = get_execution_role(),\n",
    "                                              PrimaryContainer = primary_container)\n",
    "\n",
    "print(create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "da24b67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint configuration arn:  arn:aws:sagemaker:us-east-2:831536787935:endpoint-config/mme-hf-POC-V1-2023-06-05-13-44-06\n"
     ]
    }
   ],
   "source": [
    "endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName =ENDPOINT_NAME,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "        'InstanceType':'ml.m5.2xlarge',\n",
    "        'InitialInstanceCount':1,\n",
    "        'ModelName': ENDPOINT_NAME,\n",
    "        'VariantName':'AllTraffic',\n",
    "        'InitialVariantWeight':1\n",
    "        }\n",
    "    ])\n",
    "\n",
    "print('Endpoint configuration arn:  {}'.format(endpoint_config_response['EndpointConfigArn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "645c1c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EndpointArn = arn:aws:sagemaker:us-east-2:831536787935:endpoint/mme-hf-POC-V1-2023-06-05-13-44-06\n"
     ]
    }
   ],
   "source": [
    "endpoint_params = {\n",
    "    'EndpointName': ENDPOINT_NAME,\n",
    "    'EndpointConfigName':ENDPOINT_NAME,\n",
    "}\n",
    "endpoint_response = sm_client.create_endpoint(**endpoint_params)\n",
    "print('EndpointArn = {}'.format(endpoint_response['EndpointArn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "182f8ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "waiter=sm_client.get_waiter(\"endpoint_in_service\")\n",
    "waiter.wait(EndpointName=ENDPOINT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1ebbf547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mme-hf-POC-V1-2023-06-05-11-44-37'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENDPOINT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9485ddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Let us define a client to play with autoscaling options\n",
    "asg_client = boto3.client('application-autoscaling') # Common class representing Application Auto Scaling for SageMaker amongst other services\n",
    "\n",
    "# the resource type is variant and the unique identifier is the resource ID.\n",
    "# Example: endpoint/my-bert-fine-tuned/variant/AllTraffic .\n",
    "resource_id=f\"endpoint/{ENDPOINT_NAME}/variant/AllTraffic\"\n",
    "\n",
    "# scaling configuration\n",
    "response = asg_client.register_scalable_target(\n",
    "    ServiceNamespace='sagemaker', #\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "    MinCapacity=1,\n",
    "    MaxCapacity=3\n",
    ")\n",
    "\n",
    "\n",
    "response = asg_client.put_scaling_policy(\n",
    "    PolicyName=f'CPUUtil-ScalingPolicy-{ENDPOINT_NAME}',\n",
    "    ServiceNamespace='sagemaker',\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "    PolicyType='TargetTrackingScaling',\n",
    "    TargetTrackingScalingPolicyConfiguration={\n",
    "        'TargetValue': 50.0, # threshold\n",
    "        'CustomizedMetricSpecification':\n",
    "        {\n",
    "            'MetricName': 'CPUUtilization',\n",
    "            'Namespace': '/aws/sagemaker/Endpoints',\n",
    "            'Dimensions': [\n",
    "                {'Name': 'EndpointName', 'Value': ENDPOINT_NAME },\n",
    "                {'Name': 'VariantName','Value': 'AllTraffic'}\n",
    "            ],\n",
    "            'Statistic': 'Average', # Possible - 'Statistic': 'Average'|'Minimum'|'Maximum'|'SampleCount'|'Sum'\n",
    "            'Unit': 'Percent'\n",
    "        },\n",
    "        'ScaleInCooldown': 120, # duration until scale in\n",
    "        'ScaleOutCooldown': 5 # duration between scale out\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580c42eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a08b8e7d",
   "metadata": {},
   "source": [
    "# Endpoint Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7d5c3e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen1='the universe mirrored in a puddleisnt it amazing how there always seems to be another bottle of bheer therealeph one bottles of beer on the wall aleph one null bottles of beer\\tyou too are a puddle\\tas above so below'\n",
    "sen2='the universe mirrored in a puddleisnt it amazing how there always seems to be another bottle of bheer therealeph one bottles of beer on the wall aleph one null bottles of beer\\tyou too are a puddle\\tas above so below'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cd0608e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "v=[{\"text\":sen1,\"id\":1},{\"text\":sen2,\"id\":2}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6ad1d0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "client = boto3.client('sagemaker-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "49141b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"score\": 0.09118082374334335,\n",
      "    \"Categ\": 17,\n",
      "    \"pred\": \"l1\",\n",
      "    \"probabs\": {\n",
      "      \"0\": 0.04393492639064789,\n",
      "      \"1\": 0.047898419201374054,\n",
      "      \"2\": 0.035997066646814346,\n",
      "      \"3\": 0.04286786913871765,\n",
      "      \"4\": 0.024708978831768036,\n",
      "      \"5\": 0.04014800488948822,\n",
      "      \"6\": 0.04083900526165962,\n",
      "      \"7\": 0.06763872504234314,\n",
      "      \"8\": 0.07068825513124466,\n",
      "      \"9\": 0.05222117155790329,\n",
      "      \"10\": 0.07997382432222366,\n",
      "      \"11\": 0.026193739846348763,\n",
      "      \"12\": 0.03541635721921921,\n",
      "      \"13\": 0.07945353537797928,\n",
      "      \"14\": 0.04111085459589958,\n",
      "      \"15\": 0.04082481935620308,\n",
      "      \"16\": 0.04097103700041771,\n",
      "      \"17\": 0.09118082374334335,\n",
      "      \"18\": 0.044053815305233,\n",
      "      \"19\": 0.053878821432590485\n",
      "    },\n",
      "    \"text\": \"the universe mirrored in a puddleisnt it amazing how there always seems to be another bottle of bheer therealeph one bottles of beer on the wall aleph one null bottles of beer\\tyou too are a puddle\\tas above so below\",\n",
      "    \"id\": 1\n",
      "  },\n",
      "  {\n",
      "    \"score\": 0.09118082374334335,\n",
      "    \"Categ\": 17,\n",
      "    \"pred\": \"l1\",\n",
      "    \"probabs\": {\n",
      "      \"0\": 0.04393492639064789,\n",
      "      \"1\": 0.047898419201374054,\n",
      "      \"2\": 0.035997066646814346,\n",
      "      \"3\": 0.04286786913871765,\n",
      "      \"4\": 0.024708978831768036,\n",
      "      \"5\": 0.04014800488948822,\n",
      "      \"6\": 0.04083900526165962,\n",
      "      \"7\": 0.06763872504234314,\n",
      "      \"8\": 0.07068825513124466,\n",
      "      \"9\": 0.05222117155790329,\n",
      "      \"10\": 0.07997382432222366,\n",
      "      \"11\": 0.026193739846348763,\n",
      "      \"12\": 0.03541635721921921,\n",
      "      \"13\": 0.07945353537797928,\n",
      "      \"14\": 0.04111085459589958,\n",
      "      \"15\": 0.04082481935620308,\n",
      "      \"16\": 0.04097103700041771,\n",
      "      \"17\": 0.09118082374334335,\n",
      "      \"18\": 0.044053815305233,\n",
      "      \"19\": 0.053878821432590485\n",
      "    },\n",
      "    \"text\": \"the universe mirrored in a puddleisnt it amazing how there always seems to be another bottle of bheer therealeph one bottles of beer on the wall aleph one null bottles of beer\\tyou too are a puddle\\tas above so below\",\n",
      "    \"id\": 2\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "EndpointName=ENDPOINT_NAME,\n",
    "ContentType=\"application/json\",\n",
    "Accept=\"application/json\",\n",
    "TargetModel=\"model2.tar.gz\",\n",
    "Body=json.dumps(v)\n",
    ")\n",
    "print(response['Body'].read().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4efd3300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"score\": 0.0762203261256218,\n",
      "    \"Categ\": 12,\n",
      "    \"pred\": \"m\",\n",
      "    \"probabs\": {\n",
      "      \"0\": 0.053064700216054916,\n",
      "      \"1\": 0.03383437171578407,\n",
      "      \"2\": 0.023381473496556282,\n",
      "      \"3\": 0.06128808110952377,\n",
      "      \"4\": 0.04226318374276161,\n",
      "      \"5\": 0.0382646769285202,\n",
      "      \"6\": 0.04201752692461014,\n",
      "      \"7\": 0.06270086020231247,\n",
      "      \"8\": 0.07121488451957703,\n",
      "      \"9\": 0.05647360533475876,\n",
      "      \"10\": 0.057041436433792114,\n",
      "      \"11\": 0.02902052365243435,\n",
      "      \"12\": 0.0762203261256218,\n",
      "      \"13\": 0.061086080968379974,\n",
      "      \"14\": 0.0694165751338005,\n",
      "      \"15\": 0.048459939658641815,\n",
      "      \"16\": 0.0401015505194664,\n",
      "      \"17\": 0.04761810600757599,\n",
      "      \"18\": 0.03600163385272026,\n",
      "      \"19\": 0.05053044855594635\n",
      "    },\n",
      "    \"text\": \"the universe mirrored in a puddleisnt it amazing how there always seems to be another bottle of bheer therealeph one bottles of beer on the wall aleph one null bottles of beer\\tyou too are a puddle\\tas above so below\",\n",
      "    \"id\": 1\n",
      "  },\n",
      "  {\n",
      "    \"score\": 0.0762203261256218,\n",
      "    \"Categ\": 12,\n",
      "    \"pred\": \"m\",\n",
      "    \"probabs\": {\n",
      "      \"0\": 0.053064700216054916,\n",
      "      \"1\": 0.03383437171578407,\n",
      "      \"2\": 0.023381473496556282,\n",
      "      \"3\": 0.06128808110952377,\n",
      "      \"4\": 0.04226318374276161,\n",
      "      \"5\": 0.0382646769285202,\n",
      "      \"6\": 0.04201752692461014,\n",
      "      \"7\": 0.06270086020231247,\n",
      "      \"8\": 0.07121488451957703,\n",
      "      \"9\": 0.05647360533475876,\n",
      "      \"10\": 0.057041436433792114,\n",
      "      \"11\": 0.02902052365243435,\n",
      "      \"12\": 0.0762203261256218,\n",
      "      \"13\": 0.061086080968379974,\n",
      "      \"14\": 0.0694165751338005,\n",
      "      \"15\": 0.048459939658641815,\n",
      "      \"16\": 0.0401015505194664,\n",
      "      \"17\": 0.04761810600757599,\n",
      "      \"18\": 0.03600163385272026,\n",
      "      \"19\": 0.05053044855594635\n",
      "    },\n",
      "    \"text\": \"the universe mirrored in a puddleisnt it amazing how there always seems to be another bottle of bheer therealeph one bottles of beer on the wall aleph one null bottles of beer\\tyou too are a puddle\\tas above so below\",\n",
      "    \"id\": 2\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "EndpointName=ENDPOINT_NAME,\n",
    "ContentType=\"application/json\",\n",
    "Accept=\"application/json\",\n",
    "TargetModel=\"model1.tar.gz\",\n",
    "Body=json.dumps(v)\n",
    ")\n",
    "print(response['Body'].read().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2ce816e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"score\": 0.09118082374334335,\n",
      "    \"Categ\": 17,\n",
      "    \"pred\": \"l1\",\n",
      "    \"probabs\": {\n",
      "      \"0\": 0.04393492639064789,\n",
      "      \"1\": 0.047898419201374054,\n",
      "      \"2\": 0.035997066646814346,\n",
      "      \"3\": 0.04286786913871765,\n",
      "      \"4\": 0.024708978831768036,\n",
      "      \"5\": 0.04014800488948822,\n",
      "      \"6\": 0.04083900526165962,\n",
      "      \"7\": 0.06763872504234314,\n",
      "      \"8\": 0.07068825513124466,\n",
      "      \"9\": 0.05222117155790329,\n",
      "      \"10\": 0.07997382432222366,\n",
      "      \"11\": 0.026193739846348763,\n",
      "      \"12\": 0.03541635721921921,\n",
      "      \"13\": 0.07945353537797928,\n",
      "      \"14\": 0.04111085459589958,\n",
      "      \"15\": 0.04082481935620308,\n",
      "      \"16\": 0.04097103700041771,\n",
      "      \"17\": 0.09118082374334335,\n",
      "      \"18\": 0.044053815305233,\n",
      "      \"19\": 0.053878821432590485\n",
      "    },\n",
      "    \"text\": \"the universe mirrored in a puddleisnt it amazing how there always seems to be another bottle of bheer therealeph one bottles of beer on the wall aleph one null bottles of beer\\tyou too are a puddle\\tas above so below\",\n",
      "    \"id\": 1\n",
      "  },\n",
      "  {\n",
      "    \"score\": 0.09118082374334335,\n",
      "    \"Categ\": 17,\n",
      "    \"pred\": \"l1\",\n",
      "    \"probabs\": {\n",
      "      \"0\": 0.04393492639064789,\n",
      "      \"1\": 0.047898419201374054,\n",
      "      \"2\": 0.035997066646814346,\n",
      "      \"3\": 0.04286786913871765,\n",
      "      \"4\": 0.024708978831768036,\n",
      "      \"5\": 0.04014800488948822,\n",
      "      \"6\": 0.04083900526165962,\n",
      "      \"7\": 0.06763872504234314,\n",
      "      \"8\": 0.07068825513124466,\n",
      "      \"9\": 0.05222117155790329,\n",
      "      \"10\": 0.07997382432222366,\n",
      "      \"11\": 0.026193739846348763,\n",
      "      \"12\": 0.03541635721921921,\n",
      "      \"13\": 0.07945353537797928,\n",
      "      \"14\": 0.04111085459589958,\n",
      "      \"15\": 0.04082481935620308,\n",
      "      \"16\": 0.04097103700041771,\n",
      "      \"17\": 0.09118082374334335,\n",
      "      \"18\": 0.044053815305233,\n",
      "      \"19\": 0.053878821432590485\n",
      "    },\n",
      "    \"text\": \"the universe mirrored in a puddleisnt it amazing how there always seems to be another bottle of bheer therealeph one bottles of beer on the wall aleph one null bottles of beer\\tyou too are a puddle\\tas above so below\",\n",
      "    \"id\": 2\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "EndpointName=ENDPOINT_NAME,\n",
    "ContentType=\"application/json\",\n",
    "Accept=\"application/json\",\n",
    "TargetModel=\"model2.tar.gz\",\n",
    "Body=json.dumps(v)\n",
    ")\n",
    "print(response['Body'].read().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f3efc633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"score\": 0.10249396413564682,\n",
      "    \"Categ\": 15,\n",
      "    \"pred\": \"j1\",\n",
      "    \"probabs\": {\n",
      "      \"0\": 0.05833074823021889,\n",
      "      \"1\": 0.03819238767027855,\n",
      "      \"2\": 0.03585965931415558,\n",
      "      \"3\": 0.05405878275632858,\n",
      "      \"4\": 0.0336628258228302,\n",
      "      \"5\": 0.03182928264141083,\n",
      "      \"6\": 0.035747431218624115,\n",
      "      \"7\": 0.05438819155097008,\n",
      "      \"8\": 0.06668586283922195,\n",
      "      \"9\": 0.04516938328742981,\n",
      "      \"10\": 0.050032839179039,\n",
      "      \"11\": 0.03866000846028328,\n",
      "      \"12\": 0.06522325426340103,\n",
      "      \"13\": 0.06857302039861679,\n",
      "      \"14\": 0.053612589836120605,\n",
      "      \"15\": 0.10249396413564682,\n",
      "      \"16\": 0.03439391031861305,\n",
      "      \"17\": 0.0440681166946888,\n",
      "      \"18\": 0.04143171384930611,\n",
      "      \"19\": 0.04758596420288086\n",
      "    },\n",
      "    \"text\": \"the universe mirrored in a puddleisnt it amazing how there always seems to be another bottle of bheer therealeph one bottles of beer on the wall aleph one null bottles of beer\\tyou too are a puddle\\tas above so below\",\n",
      "    \"id\": 1\n",
      "  },\n",
      "  {\n",
      "    \"score\": 0.10249396413564682,\n",
      "    \"Categ\": 15,\n",
      "    \"pred\": \"j1\",\n",
      "    \"probabs\": {\n",
      "      \"0\": 0.05833074823021889,\n",
      "      \"1\": 0.03819238767027855,\n",
      "      \"2\": 0.03585965931415558,\n",
      "      \"3\": 0.05405878275632858,\n",
      "      \"4\": 0.0336628258228302,\n",
      "      \"5\": 0.03182928264141083,\n",
      "      \"6\": 0.035747431218624115,\n",
      "      \"7\": 0.05438819155097008,\n",
      "      \"8\": 0.06668586283922195,\n",
      "      \"9\": 0.04516938328742981,\n",
      "      \"10\": 0.050032839179039,\n",
      "      \"11\": 0.03866000846028328,\n",
      "      \"12\": 0.06522325426340103,\n",
      "      \"13\": 0.06857302039861679,\n",
      "      \"14\": 0.053612589836120605,\n",
      "      \"15\": 0.10249396413564682,\n",
      "      \"16\": 0.03439391031861305,\n",
      "      \"17\": 0.0440681166946888,\n",
      "      \"18\": 0.04143171384930611,\n",
      "      \"19\": 0.04758596420288086\n",
      "    },\n",
      "    \"text\": \"the universe mirrored in a puddleisnt it amazing how there always seems to be another bottle of bheer therealeph one bottles of beer on the wall aleph one null bottles of beer\\tyou too are a puddle\\tas above so below\",\n",
      "    \"id\": 2\n",
      "  }\n",
      "]\n",
      "CPU times: user 45.2 ms, sys: 4.6 ms, total: 49.8 ms\n",
      "Wall time: 7.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import boto3\n",
    "import json\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "EndpointName=ENDPOINT_NAME,\n",
    "ContentType=\"application/json\",\n",
    "Accept=\"application/json\",\n",
    "TargetModel=\"model3.tar.gz\",\n",
    "Body=json.dumps(v)\n",
    ")\n",
    "print(response['Body'].read().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b63ecde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_handler(event, context=\"None\"):\n",
    "        all=[]\n",
    "#         event=eval(event[\"body\"])\n",
    "        print(event)\n",
    "        event=json.loads(json.dumps(event))\n",
    "        response1 = client.invoke_endpoint(EndpointName=\"mme-hf-POC-V1-2023-06-04-09-06-29\",ContentType=\"application/json\",Accept=\"application/json\",TargetModel=\"model1.tar.gz\",Body=json.dumps(v))\n",
    "        response2 = client.invoke_endpoint(EndpointName=\"mme-hf-POC-V1-2023-06-04-09-06-29\",ContentType=\"application/json\",Accept=\"application/json\",TargetModel=\"model2.tar.gz\",Body=json.dumps(v))\n",
    "        response3 = client.invoke_endpoint(EndpointName=\"mme-hf-POC-V1-2023-06-04-09-06-29\",ContentType=\"application/json\",Accept=\"application/json\",TargetModel=\"model3.tar.gz\",Body=json.dumps(v))\n",
    "        value1=json.loads(response1['Body'].read().decode())\n",
    "        value2=json.loads(response2['Body'].read().decode())\n",
    "        value3=json.loads(response3['Body'].read().decode())\n",
    "        all.extend(value1)\n",
    "        all.extend(value2)\n",
    "        all.extend(value3)\n",
    "        return all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41ddbee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'the universe mirrored in a puddleisnt it amazing how there always seems to be another bottle of bheer therealeph one bottles of beer on the wall aleph one null bottles of beer\\tyou too are a puddle\\tas above so below', 'id': 1}, {'text': 'the universe mirrored in a puddleisnt it amazing how there always seems to be another bottle of bheer therealeph one bottles of beer on the wall aleph one null bottles of beer\\tyou too are a puddle\\tas above so below', 'id': 2}]\n"
     ]
    }
   ],
   "source": [
    "v=lambda_handler(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f3140092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d19279ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "v=[{\"score\":0.0786677822470665,\"probabs\":{\"11\":0.0734185054898262,\"12\":0.053138475865125656,\"13\":0.0645674467086792,\"14\":0.04427026957273483,\"15\":0.03951818495988846,\"16\":0.05541767179965973,\"17\":0.05795884504914284,\"18\":0.044276174157857895,\"19\":0.05284232273697853,\"0\":0.0347941555082798,\"1\":0.047643449157476425,\"2\":0.058559220284223557,\"3\":0.03778599575161934,\"4\":0.05978680029511452,\"5\":0.0786677822470665,\"6\":0.03158474713563919,\"7\":0.035702262073755264,\"8\":0.043942879885435104,\"9\":0.051764875650405884,\"10\":0.03435995429754257},\"Categ\":5,\"pred\":\"f\",\"text\":\" SEE ACCURACY IN ADULTS ?\",\"id\":31},{\"score\":0.07641265541315079,\"probabs\":{\"11\":0.06905900686979294,\"12\":0.04097370803356171,\"13\":0.07641265541315079,\"14\":0.04322277754545212,\"15\":0.057789236307144165,\"16\":0.04455627128481865,\"17\":0.06774531304836273,\"18\":0.04826144874095917,\"19\":0.0570475235581398,\"0\":0.04471467435359955,\"1\":0.06566658616065979,\"2\":0.0529228039085865,\"3\":0.04011021554470062,\"4\":0.047212518751621246,\"5\":0.055869825184345245,\"6\":0.03973971679806709,\"7\":0.028527729213237762,\"8\":0.03630654886364937,\"9\":0.04106844216585159,\"10\":0.04279303178191185},\"Categ\":13,\"pred\":\"n\",\"text\":\"50-56% of patients maintained remission (das28-hscrp 2.6)\",\"id\":32},{\"score\":0.07514258474111557,\"probabs\":{\"11\":0.05765023082494736,\"12\":0.05755647271871567,\"13\":0.07514258474111557,\"14\":0.04839545488357544,\"15\":0.046911340206861496,\"16\":0.04532558470964432,\"17\":0.05318426713347435,\"18\":0.041376255452632904,\"19\":0.06190388649702072,\"0\":0.042031336575746536,\"1\":0.05209396407008171,\"2\":0.049786075949668884,\"3\":0.04420416057109833,\"4\":0.06421200186014175,\"5\":0.0637398511171341,\"6\":0.04055355116724968,\"7\":0.03757360205054283,\"8\":0.036787837743759155,\"9\":0.04347537085413933,\"10\":0.03809618949890137},\"Categ\":13,\"pred\":\"n\",\"text\":\"Safety profile of baricitinib: All Bari dataset\",\"id\":34},{\"score\":0.07422996312379837,\"probabs\":{\"11\":0.06959327310323715,\"12\":0.06562454253435135,\"13\":0.07233278453350067,\"14\":0.04503995552659035,\"15\":0.040700286626815796,\"16\":0.04539260268211365,\"17\":0.04823519289493561,\"18\":0.03677678853273392,\"19\":0.05304485931992531,\"0\":0.03625566139817238,\"1\":0.04591182991862297,\"2\":0.056426506489515305,\"3\":0.042852871119976044,\"4\":0.06810418516397476,\"5\":0.07422996312379837,\"6\":0.03484737128019333,\"7\":0.039241041988134384,\"8\":0.05139022693037987,\"9\":0.043749529868364334,\"10\":0.030250554904341698},\"Categ\":5,\"pred\":\"f\",\"text\":\"awakenings due to itch over 16\",\"id\":34},{\"score\":0.08620596677064896,\"probabs\":{\"11\":0.08620596677064896,\"12\":0.04570329189300537,\"13\":0.0763409361243248,\"14\":0.03947865590453148,\"15\":0.05708197131752968,\"16\":0.048123329877853394,\"17\":0.06585317105054855,\"18\":0.04750034958124161,\"19\":0.05615234375,\"0\":0.03301052376627922,\"1\":0.05621261149644852,\"2\":0.058245766907930374,\"3\":0.02978755161166191,\"4\":0.05243918299674988,\"5\":0.054855793714523315,\"6\":0.03181491419672966,\"7\":0.03064623475074768,\"8\":0.04435751959681511,\"9\":0.050484549254179,\"10\":0.035705387592315674},\"Categ\":11,\"pred\":\"l\",\"text\":\"a Discontinued patients were considered as non-responders;\",\"id\":34},{\"score\":0.08329016715288162,\"probabs\":{\"11\":0.05852552875876427,\"12\":0.04928218200802803,\"13\":0.08329016715288162,\"14\":0.04763812571763992,\"15\":0.059170641005039215,\"16\":0.04568006843328476,\"17\":0.053653061389923096,\"18\":0.04153353348374367,\"19\":0.05460380017757416,\"0\":0.045776061713695526,\"1\":0.05843130871653557,\"2\":0.046965084969997406,\"3\":0.04383372887969017,\"4\":0.0456748865544796,\"5\":0.05467319115996361,\"6\":0.04252728819847107,\"7\":0.03679529204964638,\"8\":0.040985818952322006,\"9\":0.04432374984025955,\"10\":0.04663631692528725},\"Categ\":13,\"pred\":\"n\",\"text\":\"The proportion of patients achieving LDA with Olumiant + MTX was significantly higher than with adalimumab + MTX at week 12 and week 52\",\"id\":35},{\"score\":0.0786677822470665,\"probabs\":{\"11\":0.0734185054898262,\"12\":0.053138475865125656,\"13\":0.0645674467086792,\"14\":0.04427026957273483,\"15\":0.03951818495988846,\"16\":0.05541767179965973,\"17\":0.05795884504914284,\"18\":0.044276174157857895,\"19\":0.05284232273697853,\"0\":0.0347941555082798,\"1\":0.047643449157476425,\"2\":0.058559220284223557,\"3\":0.03778599575161934,\"4\":0.05978680029511452,\"5\":0.0786677822470665,\"6\":0.03158474713563919,\"7\":0.035702262073755264,\"8\":0.043942879885435104,\"9\":0.051764875650405884,\"10\":0.03435995429754257},\"Categ\":5,\"pred\":\"f\",\"text\":\" SEE ACCURACY IN ADULTS ?\",\"id\":31},{\"score\":0.07641265541315079,\"probabs\":{\"11\":0.06905900686979294,\"12\":0.04097370803356171,\"13\":0.07641265541315079,\"14\":0.04322277754545212,\"15\":0.057789236307144165,\"16\":0.04455627128481865,\"17\":0.06774531304836273,\"18\":0.04826144874095917,\"19\":0.0570475235581398,\"0\":0.04471467435359955,\"1\":0.06566658616065979,\"2\":0.0529228039085865,\"3\":0.04011021554470062,\"4\":0.047212518751621246,\"5\":0.055869825184345245,\"6\":0.03973971679806709,\"7\":0.028527729213237762,\"8\":0.03630654886364937,\"9\":0.04106844216585159,\"10\":0.04279303178191185},\"Categ\":13,\"pred\":\"n\",\"text\":\"50-56% of patients maintained remission (das28-hscrp 2.6)\",\"id\":32},{\"score\":0.07514258474111557,\"probabs\":{\"11\":0.05765023082494736,\"12\":0.05755647271871567,\"13\":0.07514258474111557,\"14\":0.04839545488357544,\"15\":0.046911340206861496,\"16\":0.04532558470964432,\"17\":0.05318426713347435,\"18\":0.041376255452632904,\"19\":0.06190388649702072,\"0\":0.042031336575746536,\"1\":0.05209396407008171,\"2\":0.049786075949668884,\"3\":0.04420416057109833,\"4\":0.06421200186014175,\"5\":0.0637398511171341,\"6\":0.04055355116724968,\"7\":0.03757360205054283,\"8\":0.036787837743759155,\"9\":0.04347537085413933,\"10\":0.03809618949890137},\"Categ\":13,\"pred\":\"n\",\"text\":\"Safety profile of baricitinib: All Bari dataset\",\"id\":34},{\"score\":0.07422996312379837,\"probabs\":{\"11\":0.06959327310323715,\"12\":0.06562454253435135,\"13\":0.07233278453350067,\"14\":0.04503995552659035,\"15\":0.040700286626815796,\"16\":0.04539260268211365,\"17\":0.04823519289493561,\"18\":0.03677678853273392,\"19\":0.05304485931992531,\"0\":0.03625566139817238,\"1\":0.04591182991862297,\"2\":0.056426506489515305,\"3\":0.042852871119976044,\"4\":0.06810418516397476,\"5\":0.07422996312379837,\"6\":0.03484737128019333,\"7\":0.039241041988134384,\"8\":0.05139022693037987,\"9\":0.043749529868364334,\"10\":0.030250554904341698},\"Categ\":5,\"pred\":\"f\",\"text\":\"awakenings due to itch over 16\",\"id\":34},{\"score\":0.08620596677064896,\"probabs\":{\"11\":0.08620596677064896,\"12\":0.04570329189300537,\"13\":0.0763409361243248,\"14\":0.03947865590453148,\"15\":0.05708197131752968,\"16\":0.048123329877853394,\"17\":0.06585317105054855,\"18\":0.04750034958124161,\"19\":0.05615234375,\"0\":0.03301052376627922,\"1\":0.05621261149644852,\"2\":0.058245766907930374,\"3\":0.02978755161166191,\"4\":0.05243918299674988,\"5\":0.054855793714523315,\"6\":0.03181491419672966,\"7\":0.03064623475074768,\"8\":0.04435751959681511,\"9\":0.050484549254179,\"10\":0.035705387592315674},\"Categ\":11,\"pred\":\"l\",\"text\":\"a Discontinued patients were considered as non-responders;\",\"id\":34},{\"score\":0.08329016715288162,\"probabs\":{\"11\":0.05852552875876427,\"12\":0.04928218200802803,\"13\":0.08329016715288162,\"14\":0.04763812571763992,\"15\":0.059170641005039215,\"16\":0.04568006843328476,\"17\":0.053653061389923096,\"18\":0.04153353348374367,\"19\":0.05460380017757416,\"0\":0.045776061713695526,\"1\":0.05843130871653557,\"2\":0.046965084969997406,\"3\":0.04383372887969017,\"4\":0.0456748865544796,\"5\":0.05467319115996361,\"6\":0.04252728819847107,\"7\":0.03679529204964638,\"8\":0.040985818952322006,\"9\":0.04432374984025955,\"10\":0.04663631692528725},\"Categ\":13,\"pred\":\"n\",\"text\":\"The proportion of patients achieving LDA with Olumiant + MTX was significantly higher than with adalimumab + MTX at week 12 and week 52\",\"id\":35},{\"score\":0.07161392271518707,\"probabs\":{\"11\":0.04035268723964691,\"12\":0.0406116247177124,\"13\":0.0643928274512291,\"14\":0.05198647826910019,\"15\":0.06164979189634323,\"16\":0.04718560725450516,\"17\":0.046289168298244476,\"18\":0.035153817385435104,\"19\":0.05515630543231964,\"0\":0.046835340559482574,\"1\":0.0294839758425951,\"2\":0.04554421827197075,\"3\":0.07161392271518707,\"4\":0.06186763942241669,\"5\":0.03344792127609253,\"6\":0.050818849354982376,\"7\":0.03936672955751419,\"8\":0.05561213567852974,\"9\":0.06607433408498764,\"10\":0.05655653029680252},\"Categ\":3,\"pred\":\"d\",\"text\":\" SEE ACCURACY IN ADULTS ?\",\"id\":31},{\"score\":0.16765771806240082,\"probabs\":{\"11\":0.03964937478303909,\"12\":0.0307786762714386,\"13\":0.16765771806240082,\"14\":0.0537228100001812,\"15\":0.027972500771284103,\"16\":0.03410036861896515,\"17\":0.0618680976331234,\"18\":0.05475699156522751,\"19\":0.046574413776397705,\"0\":0.03635594993829727,\"1\":0.07563778758049011,\"2\":0.0547444224357605,\"3\":0.04104313254356384,\"4\":0.02665884606540203,\"5\":0.04692531004548073,\"6\":0.028085438534617424,\"7\":0.062051597982645035,\"8\":0.03089076839387417,\"9\":0.041960708796978,\"10\":0.03856508806347847},\"Categ\":13,\"pred\":\"n\",\"text\":\"50-56% of patients maintained remission (das28-hscrp 2.6)\",\"id\":32},{\"score\":0.15550681948661804,\"probabs\":{\"11\":0.03936811536550522,\"12\":0.03349334001541138,\"13\":0.15550681948661804,\"14\":0.06039203330874443,\"15\":0.026066264137625694,\"16\":0.033811893314123154,\"17\":0.059158001095056534,\"18\":0.05527758225798607,\"19\":0.04501783475279808,\"0\":0.03612785413861275,\"1\":0.07790616899728775,\"2\":0.05150754004716873,\"3\":0.03515759855508804,\"4\":0.025282997637987137,\"5\":0.055473797023296356,\"6\":0.030911633744835854,\"7\":0.06860218942165375,\"8\":0.03120114468038082,\"9\":0.041929300874471664,\"10\":0.0378078855574131},\"Categ\":13,\"pred\":\"n\",\"text\":\"Safety profile of baricitinib: All Bari dataset\",\"id\":34},{\"score\":0.1593659222126007,\"probabs\":{\"11\":0.035464804619550705,\"12\":0.033989161252975464,\"13\":0.1593659222126007,\"14\":0.04602809250354767,\"15\":0.02928531914949417,\"16\":0.03307224065065384,\"17\":0.06733213365077972,\"18\":0.044933710247278214,\"19\":0.057174183428287506,\"0\":0.03866594657301903,\"1\":0.07209402322769165,\"2\":0.04763425514101982,\"3\":0.04568662494421005,\"4\":0.024899866431951523,\"5\":0.04650430381298065,\"6\":0.030026676133275032,\"7\":0.05320364236831665,\"8\":0.04166916757822037,\"9\":0.04342328757047653,\"10\":0.04954664781689644},\"Categ\":13,\"pred\":\"n\",\"text\":\"awakenings due to itch over 16\",\"id\":34},{\"score\":0.15153361856937408,\"probabs\":{\"11\":0.04391308128833771,\"12\":0.03673499822616577,\"13\":0.15153361856937408,\"14\":0.0446256659924984,\"15\":0.03344288095831871,\"16\":0.03624076023697853,\"17\":0.05632079020142555,\"18\":0.04608789458870888,\"19\":0.055711425840854645,\"0\":0.038944244384765625,\"1\":0.051296789199113846,\"2\":0.054851971566677094,\"3\":0.04556036368012428,\"4\":0.029197046533226967,\"5\":0.038453999906778336,\"6\":0.03314854949712753,\"7\":0.05106913298368454,\"8\":0.03985504060983658,\"9\":0.059651248157024384,\"10\":0.05336039885878563},\"Categ\":13,\"pred\":\"n\",\"text\":\"a Discontinued patients were considered as non-responders;\",\"id\":34},{\"score\":0.16927023231983185,\"probabs\":{\"11\":0.03820618987083435,\"12\":0.02950321137905121,\"13\":0.16927023231983185,\"14\":0.05062125623226166,\"15\":0.02767421491444111,\"16\":0.03556058183312416,\"17\":0.0639946237206459,\"18\":0.05535133555531502,\"19\":0.0547204352915287,\"0\":0.034825097769498825,\"1\":0.08999908715486526,\"2\":0.0443703792989254,\"3\":0.042134929448366165,\"4\":0.02220219373703003,\"5\":0.04599907621741295,\"6\":0.028274232521653175,\"7\":0.062090009450912476,\"8\":0.027946652844548225,\"9\":0.041481081396341324,\"10\":0.03577522933483124},\"Categ\":13,\"pred\":\"n\",\"text\":\"The proportion of patients achieving LDA with Olumiant + MTX was significantly higher than with adalimumab + MTX at week 12 and week 52\",\"id\":35},{\"score\":0.07161392271518707,\"probabs\":{\"11\":0.04035268723964691,\"12\":0.0406116247177124,\"13\":0.0643928274512291,\"14\":0.05198647826910019,\"15\":0.06164979189634323,\"16\":0.04718560725450516,\"17\":0.046289168298244476,\"18\":0.035153817385435104,\"19\":0.05515630543231964,\"0\":0.046835340559482574,\"1\":0.0294839758425951,\"2\":0.04554421827197075,\"3\":0.07161392271518707,\"4\":0.06186763942241669,\"5\":0.03344792127609253,\"6\":0.050818849354982376,\"7\":0.03936672955751419,\"8\":0.05561213567852974,\"9\":0.06607433408498764,\"10\":0.05655653029680252},\"Categ\":3,\"pred\":\"d\",\"text\":\" SEE ACCURACY IN ADULTS ?\",\"id\":31},{\"score\":0.16765771806240082,\"probabs\":{\"11\":0.03964937478303909,\"12\":0.0307786762714386,\"13\":0.16765771806240082,\"14\":0.0537228100001812,\"15\":0.027972500771284103,\"16\":0.03410036861896515,\"17\":0.0618680976331234,\"18\":0.05475699156522751,\"19\":0.046574413776397705,\"0\":0.03635594993829727,\"1\":0.07563778758049011,\"2\":0.0547444224357605,\"3\":0.04104313254356384,\"4\":0.02665884606540203,\"5\":0.04692531004548073,\"6\":0.028085438534617424,\"7\":0.062051597982645035,\"8\":0.03089076839387417,\"9\":0.041960708796978,\"10\":0.03856508806347847},\"Categ\":13,\"pred\":\"n\",\"text\":\"50-56% of patients maintained remission (das28-hscrp 2.6)\",\"id\":32},{\"score\":0.15550681948661804,\"probabs\":{\"11\":0.03936811536550522,\"12\":0.03349334001541138,\"13\":0.15550681948661804,\"14\":0.06039203330874443,\"15\":0.026066264137625694,\"16\":0.033811893314123154,\"17\":0.059158001095056534,\"18\":0.05527758225798607,\"19\":0.04501783475279808,\"0\":0.03612785413861275,\"1\":0.07790616899728775,\"2\":0.05150754004716873,\"3\":0.03515759855508804,\"4\":0.025282997637987137,\"5\":0.055473797023296356,\"6\":0.030911633744835854,\"7\":0.06860218942165375,\"8\":0.03120114468038082,\"9\":0.041929300874471664,\"10\":0.0378078855574131},\"Categ\":13,\"pred\":\"n\",\"text\":\"Safety profile of baricitinib: All Bari dataset\",\"id\":34},{\"score\":0.1593659222126007,\"probabs\":{\"11\":0.035464804619550705,\"12\":0.033989161252975464,\"13\":0.1593659222126007,\"14\":0.04602809250354767,\"15\":0.02928531914949417,\"16\":0.03307224065065384,\"17\":0.06733213365077972,\"18\":0.044933710247278214,\"19\":0.057174183428287506,\"0\":0.03866594657301903,\"1\":0.07209402322769165,\"2\":0.04763425514101982,\"3\":0.04568662494421005,\"4\":0.024899866431951523,\"5\":0.04650430381298065,\"6\":0.030026676133275032,\"7\":0.05320364236831665,\"8\":0.04166916757822037,\"9\":0.04342328757047653,\"10\":0.04954664781689644},\"Categ\":13,\"pred\":\"n\",\"text\":\"awakenings due to itch over 16\",\"id\":34},{\"score\":0.15153361856937408,\"probabs\":{\"11\":0.04391308128833771,\"12\":0.03673499822616577,\"13\":0.15153361856937408,\"14\":0.0446256659924984,\"15\":0.03344288095831871,\"16\":0.03624076023697853,\"17\":0.05632079020142555,\"18\":0.04608789458870888,\"19\":0.055711425840854645,\"0\":0.038944244384765625,\"1\":0.051296789199113846,\"2\":0.054851971566677094,\"3\":0.04556036368012428,\"4\":0.029197046533226967,\"5\":0.038453999906778336,\"6\":0.03314854949712753,\"7\":0.05106913298368454,\"8\":0.03985504060983658,\"9\":0.059651248157024384,\"10\":0.05336039885878563},\"Categ\":13,\"pred\":\"n\",\"text\":\"a Discontinued patients were considered as non-responders;\",\"id\":34},{\"score\":0.16927023231983185,\"probabs\":{\"11\":0.03820618987083435,\"12\":0.02950321137905121,\"13\":0.16927023231983185,\"14\":0.05062125623226166,\"15\":0.02767421491444111,\"16\":0.03556058183312416,\"17\":0.0639946237206459,\"18\":0.05535133555531502,\"19\":0.0547204352915287,\"0\":0.034825097769498825,\"1\":0.08999908715486526,\"2\":0.0443703792989254,\"3\":0.042134929448366165,\"4\":0.02220219373703003,\"5\":0.04599907621741295,\"6\":0.028274232521653175,\"7\":0.062090009450912476,\"8\":0.027946652844548225,\"9\":0.041481081396341324,\"10\":0.03577522933483124},\"Categ\":13,\"pred\":\"n\",\"text\":\"The proportion of patients achieving LDA with Olumiant + MTX was significantly higher than with adalimumab + MTX at week 12 and week 52\",\"id\":35},{\"score\":0.12634479999542236,\"probabs\":{\"11\":0.06247119605541229,\"12\":0.050037652254104614,\"13\":0.12634479999542236,\"14\":0.03795496001839638,\"15\":0.07269198447465897,\"16\":0.027252783998847008,\"17\":0.059340041130781174,\"18\":0.05814190208911896,\"19\":0.03066185675561428,\"0\":0.08061342686414719,\"1\":0.03354671597480774,\"2\":0.031937357038259506,\"3\":0.024694904685020447,\"4\":0.02910773642361164,\"5\":0.03633850812911987,\"6\":0.028910353779792786,\"7\":0.054589737206697464,\"8\":0.04773753881454468,\"9\":0.061636339873075485,\"10\":0.045990291982889175},\"Categ\":13,\"pred\":\"n\",\"text\":\" SEE ACCURACY IN ADULTS ?\",\"id\":31},{\"score\":0.1367417573928833,\"probabs\":{\"11\":0.050896987318992615,\"12\":0.03911470249295235,\"13\":0.1367417573928833,\"14\":0.044757746160030365,\"15\":0.07390004396438599,\"16\":0.027263911440968513,\"17\":0.078951396048069,\"18\":0.05710581690073013,\"19\":0.034363675862550735,\"0\":0.07538915425539017,\"1\":0.0314745232462883,\"2\":0.03379067778587341,\"3\":0.027952764183282852,\"4\":0.02624187432229519,\"5\":0.02886245958507061,\"6\":0.028559545055031776,\"7\":0.049197643995285034,\"8\":0.04167266935110092,\"9\":0.07045908272266388,\"10\":0.04330356791615486},\"Categ\":13,\"pred\":\"n\",\"text\":\"50-56% of patients maintained remission (das28-hscrp 2.6)\",\"id\":32},{\"score\":0.1276746690273285,\"probabs\":{\"11\":0.0699823871254921,\"12\":0.06492919474840164,\"13\":0.1276746690273285,\"14\":0.06334757804870605,\"15\":0.06472764164209366,\"16\":0.023341771215200424,\"17\":0.050270646810531616,\"18\":0.04907143861055374,\"19\":0.040460627526044846,\"0\":0.05867870897054672,\"1\":0.039756033569574356,\"2\":0.03360401839017868,\"3\":0.032999467104673386,\"4\":0.03317135199904442,\"5\":0.039395805448293686,\"6\":0.03935551643371582,\"7\":0.053492527455091476,\"8\":0.04676760360598564,\"9\":0.039962515234947205,\"10\":0.02901049703359604},\"Categ\":13,\"pred\":\"n\",\"text\":\"Safety profile of baricitinib: All Bari dataset\",\"id\":34},{\"score\":0.13062074780464172,\"probabs\":{\"11\":0.050332002341747284,\"12\":0.03898337110877037,\"13\":0.13062074780464172,\"14\":0.04934326186776161,\"15\":0.05966152250766754,\"16\":0.02854563295841217,\"17\":0.06559865921735764,\"18\":0.05329029634594917,\"19\":0.0334944985806942,\"0\":0.07434457540512085,\"1\":0.03296084329485893,\"2\":0.03008386306464672,\"3\":0.029992472380399704,\"4\":0.022911272943019867,\"5\":0.030816378071904182,\"6\":0.03294844180345535,\"7\":0.05940934270620346,\"8\":0.04975578561425209,\"9\":0.07614672183990479,\"10\":0.0507601723074913},\"Categ\":13,\"pred\":\"n\",\"text\":\"awakenings due to itch over 16\",\"id\":34},{\"score\":0.1272536665201187,\"probabs\":{\"11\":0.06301098316907883,\"12\":0.037651415914297104,\"13\":0.1272536665201187,\"14\":0.04191889613866806,\"15\":0.06258834898471832,\"16\":0.025729723274707794,\"17\":0.06925690174102783,\"18\":0.06509364396333694,\"19\":0.0289076566696167,\"0\":0.08100893348455429,\"1\":0.03217019513249397,\"2\":0.03152613714337349,\"3\":0.025309674441814423,\"4\":0.02690909057855606,\"5\":0.03174332529306412,\"6\":0.027309702709317207,\"7\":0.05365825444459915,\"8\":0.04302874952554703,\"9\":0.0740022137761116,\"10\":0.051922425627708435},\"Categ\":13,\"pred\":\"n\",\"text\":\"a Discontinued patients were considered as non-responders;\",\"id\":34},{\"score\":0.13336044549942017,\"probabs\":{\"11\":0.05540933832526207,\"12\":0.04142050817608833,\"13\":0.13336044549942017,\"14\":0.05768578499555588,\"15\":0.07768985629081726,\"16\":0.026753198355436325,\"17\":0.06462326645851135,\"18\":0.05655119940638542,\"19\":0.04110392555594444,\"0\":0.06926074624061584,\"1\":0.03136739879846573,\"2\":0.033163025975227356,\"3\":0.028852013871073723,\"4\":0.030042679980397224,\"5\":0.03045685403048992,\"6\":0.038417547941207886,\"7\":0.04936453327536583,\"8\":0.046603377908468246,\"9\":0.05401873216032982,\"10\":0.03385550528764725},\"Categ\":13,\"pred\":\"n\",\"text\":\"The proportion of patients achieving LDA with Olumiant + MTX was significantly higher than with adalimumab + MTX at week 12 and week 52\",\"id\":35},{\"score\":0.12634479999542236,\"probabs\":{\"11\":0.06247119605541229,\"12\":0.050037652254104614,\"13\":0.12634479999542236,\"14\":0.03795496001839638,\"15\":0.07269198447465897,\"16\":0.027252783998847008,\"17\":0.059340041130781174,\"18\":0.05814190208911896,\"19\":0.03066185675561428,\"0\":0.08061342686414719,\"1\":0.03354671597480774,\"2\":0.031937357038259506,\"3\":0.024694904685020447,\"4\":0.02910773642361164,\"5\":0.03633850812911987,\"6\":0.028910353779792786,\"7\":0.054589737206697464,\"8\":0.04773753881454468,\"9\":0.061636339873075485,\"10\":0.045990291982889175},\"Categ\":13,\"pred\":\"n\",\"text\":\" SEE ACCURACY IN ADULTS ?\",\"id\":31},{\"score\":0.1367417573928833,\"probabs\":{\"11\":0.050896987318992615,\"12\":0.03911470249295235,\"13\":0.1367417573928833,\"14\":0.044757746160030365,\"15\":0.07390004396438599,\"16\":0.027263911440968513,\"17\":0.078951396048069,\"18\":0.05710581690073013,\"19\":0.034363675862550735,\"0\":0.07538915425539017,\"1\":0.0314745232462883,\"2\":0.03379067778587341,\"3\":0.027952764183282852,\"4\":0.02624187432229519,\"5\":0.02886245958507061,\"6\":0.028559545055031776,\"7\":0.049197643995285034,\"8\":0.04167266935110092,\"9\":0.07045908272266388,\"10\":0.04330356791615486},\"Categ\":13,\"pred\":\"n\",\"text\":\"50-56% of patients maintained remission (das28-hscrp 2.6)\",\"id\":32},{\"score\":0.1276746690273285,\"probabs\":{\"11\":0.0699823871254921,\"12\":0.06492919474840164,\"13\":0.1276746690273285,\"14\":0.06334757804870605,\"15\":0.06472764164209366,\"16\":0.023341771215200424,\"17\":0.050270646810531616,\"18\":0.04907143861055374,\"19\":0.040460627526044846,\"0\":0.05867870897054672,\"1\":0.039756033569574356,\"2\":0.03360401839017868,\"3\":0.032999467104673386,\"4\":0.03317135199904442,\"5\":0.039395805448293686,\"6\":0.03935551643371582,\"7\":0.053492527455091476,\"8\":0.04676760360598564,\"9\":0.039962515234947205,\"10\":0.02901049703359604},\"Categ\":13,\"pred\":\"n\",\"text\":\"Safety profile of baricitinib: All Bari dataset\",\"id\":34},{\"score\":0.13062074780464172,\"probabs\":{\"11\":0.050332002341747284,\"12\":0.03898337110877037,\"13\":0.13062074780464172,\"14\":0.04934326186776161,\"15\":0.05966152250766754,\"16\":0.02854563295841217,\"17\":0.06559865921735764,\"18\":0.05329029634594917,\"19\":0.0334944985806942,\"0\":0.07434457540512085,\"1\":0.03296084329485893,\"2\":0.03008386306464672,\"3\":0.029992472380399704,\"4\":0.022911272943019867,\"5\":0.030816378071904182,\"6\":0.03294844180345535,\"7\":0.05940934270620346,\"8\":0.04975578561425209,\"9\":0.07614672183990479,\"10\":0.0507601723074913},\"Categ\":13,\"pred\":\"n\",\"text\":\"awakenings due to itch over 16\",\"id\":34},{\"score\":0.1272536665201187,\"probabs\":{\"11\":0.06301098316907883,\"12\":0.037651415914297104,\"13\":0.1272536665201187,\"14\":0.04191889613866806,\"15\":0.06258834898471832,\"16\":0.025729723274707794,\"17\":0.06925690174102783,\"18\":0.06509364396333694,\"19\":0.0289076566696167,\"0\":0.08100893348455429,\"1\":0.03217019513249397,\"2\":0.03152613714337349,\"3\":0.025309674441814423,\"4\":0.02690909057855606,\"5\":0.03174332529306412,\"6\":0.027309702709317207,\"7\":0.05365825444459915,\"8\":0.04302874952554703,\"9\":0.0740022137761116,\"10\":0.051922425627708435},\"Categ\":13,\"pred\":\"n\",\"text\":\"a Discontinued patients were considered as non-responders;\",\"id\":34},{\"score\":0.13336044549942017,\"probabs\":{\"11\":0.05540933832526207,\"12\":0.04142050817608833,\"13\":0.13336044549942017,\"14\":0.05768578499555588,\"15\":0.07768985629081726,\"16\":0.026753198355436325,\"17\":0.06462326645851135,\"18\":0.05655119940638542,\"19\":0.04110392555594444,\"0\":0.06926074624061584,\"1\":0.03136739879846573,\"2\":0.033163025975227356,\"3\":0.028852013871073723,\"4\":0.030042679980397224,\"5\":0.03045685403048992,\"6\":0.038417547941207886,\"7\":0.04936453327536583,\"8\":0.046603377908468246,\"9\":0.05401873216032982,\"10\":0.03385550528764725},\"Categ\":13,\"pred\":\"n\",\"text\":\"The proportion of patients achieving LDA with Olumiant + MTX was significantly higher than with adalimumab + MTX at week 12 and week 52\",\"id\":35}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d2b0925d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d6af80a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.07641265541315079,\n",
       " 'probabs': {'11': 0.06905900686979294,\n",
       "  '12': 0.04097370803356171,\n",
       "  '13': 0.07641265541315079,\n",
       "  '14': 0.04322277754545212,\n",
       "  '15': 0.057789236307144165,\n",
       "  '16': 0.04455627128481865,\n",
       "  '17': 0.06774531304836273,\n",
       "  '18': 0.04826144874095917,\n",
       "  '19': 0.0570475235581398,\n",
       "  '0': 0.04471467435359955,\n",
       "  '1': 0.06566658616065979,\n",
       "  '2': 0.0529228039085865,\n",
       "  '3': 0.04011021554470062,\n",
       "  '4': 0.047212518751621246,\n",
       "  '5': 0.055869825184345245,\n",
       "  '6': 0.03973971679806709,\n",
       "  '7': 0.028527729213237762,\n",
       "  '8': 0.03630654886364937,\n",
       "  '9': 0.04106844216585159,\n",
       "  '10': 0.04279303178191185},\n",
       " 'Categ': 13,\n",
       " 'pred': 'n',\n",
       " 'text': '50-56% of patients maintained remission (das28-hscrp 2.6)',\n",
       " 'id': 32}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "545b11be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([\n",
    "    {\"id\": 31, \"text\": \" SEE ACCURACY IN ADULTS →\"\n",
    "    },\n",
    "    {\"id\": 32, \"text\": \"50-56% of patients maintained remission (das28-hscrp 2.6)\"\n",
    "    },\n",
    "    {\"id\": 34, \"text\": \"Safety profile of baricitinib: All Bari dataset\"\n",
    "    },\n",
    "    {\"id\":34,\"text\": \"awakenings due to itch over 16\"\n",
    "    },\n",
    "    {\"id\":34,\"text\": \"a Discontinued patients were considered as non-responders;\"\n",
    "    },\n",
    "    {\"id\":35,\"text\": \"The proportion of patients achieving LDA with Olumiant + MTX was significantly higher than with adalimumab + MTX at week 12 and week 52\"\n",
    "    },\n",
    "    {\"id\": 31, \"text\": \" SEE ACCURACY IN ADULTS →\"\n",
    "    },\n",
    "    {\"id\": 32, \"text\": \"50-56% of patients maintained remission (das28-hscrp 2.6)\"\n",
    "    },\n",
    "    {\"id\": 34, \"text\": \"Safety profile of baricitinib: All Bari dataset\"\n",
    "    },\n",
    "    {\"id\":34,\"text\": \"awakenings due to itch over 16\"\n",
    "    },\n",
    "    {\"id\":34,\"text\": \"a Discontinued patients were considered as non-responders;\"\n",
    "    },\n",
    "    {\"id\":35,\"text\": \"The proportion of patients achieving LDA with Olumiant + MTX was significantly higher than with adalimumab + MTX at week 12 and week 52\"\n",
    "    }\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "82d194f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([{\"text\": \"i am sure some bashers of pens fans are pretty confused about the lackof any kind of posts about the recent pens \\nmassacre of the devils actuallyi am  bit puzzled too and a bit relieved however i am going to put an endto nonpittsburghers \\nrelief with a bit of praise for the pens man theyare killing those devils worse than i thought jagr just showed you why \\nhe is much better than his regular season stats he is also a lotfo fun to watch in the playoffs bowman should let jagr \\nhave a lot offun in the next couple of games since the pens are going to beat the pulp out of jerseyanyway i was very \\ndisappointed not to see the islanders lose the finalregular season game pens rule\",\n",
    "  \"id\": \"1\"},\n",
    "   {\"text\": \"i am sure some bashers of pens fans are pretty confused about the lackof any kind of posts about the recent pens \\nmassacre of the devils actuallyi am  bit puzzled too and a bit relieved however i am going to put an endto nonpittsburghers \\nrelief with a bit of praise for the pens man theyare killing those devils worse than i thought jagr just showed you why \\nhe is much better than his regular season stats he is also a lotfo fun to watch in the playoffs bowman should let jagr \\nhave a lot offun in the next couple of games since the pens are going to beat the pulp out of jerseyanyway i was very \\ndisappointed not to see the islanders lose the finalregular season game pens rule\",\n",
    "  \"id\": \"1\"},\n",
    "  {\"text\": \"i am sure some bashers of pens fans are pretty confused about the lackof any kind of posts about the recent pens \\nmassacre of the devils actuallyi am  bit puzzled too and a bit relieved however i am going to put an endto nonpittsburghers \\nrelief with a bit of praise for the pens man theyare killing those devils worse than i thought jagr just showed you why \\nhe is much better than his regular season stats he is also a lotfo fun to watch in the playoffs bowman should let jagr \\nhave a lot offun in the next couple of games since the pens are going to beat the pulp out of jerseyanyway i was very \\ndisappointed not to see the islanders lose the finalregular season game pens rule\",\n",
    "  \"id\": \"1\"},\n",
    "   {\"text\": \"i am sure some bashers of pens fans are pretty confused about the lackof any kind of posts about the recent pens \\nmassacre of the devils actuallyi am  bit puzzled too and a bit relieved however i am going to put an endto nonpittsburghers \\nrelief with a bit of praise for the pens man theyare killing those devils worse than i thought jagr just showed you why \\nhe is much better than his regular season stats he is also a lotfo fun to watch in the playoffs bowman should let jagr \\nhave a lot offun in the next couple of games since the pens are going to beat the pulp out of jerseyanyway i was very \\ndisappointed not to see the islanders lose the finalregular season game pens rule\",\n",
    "  \"id\": \"1\"},\n",
    "  {\"text\": \"i am sure some bashers of pens fans are pretty confused about the lackof any kind of posts about the recent pens \\nmassacre of the devils actuallyi am  bit puzzled too and a bit relieved however i am going to put an endto nonpittsburghers \\nrelief with a bit of praise for the pens man theyare killing those devils worse than i thought jagr just showed you why \\nhe is much better than his regular season stats he is also a lotfo fun to watch in the playoffs bowman should let jagr \\nhave a lot offun in the next couple of games since the pens are going to beat the pulp out of jerseyanyway i was very \\ndisappointed not to see the islanders lose the finalregular season game pens rule\",\n",
    "  \"id\": \"1\"},\n",
    "   {\"text\": \"i am sure some bashers of pens fans are pretty confused about the lackof any kind of posts about the recent pens \\nmassacre of the devils actuallyi am  bit puzzled too and a bit relieved however i am going to put an endto nonpittsburghers \\nrelief with a bit of praise for the pens man theyare killing those devils worse than i thought jagr just showed you why \\nhe is much better than his regular season stats he is also a lotfo fun to watch in the playoffs bowman should let jagr \\nhave a lot offun in the next couple of games since the pens are going to beat the pulp out of jerseyanyway i was very \\ndisappointed not to see the islanders lose the finalregular season game pens rule\",\n",
    "  \"id\": \"1\"},\n",
    "  {\"text\": \"i am sure some bashers of pens fans are pretty confused about the lackof any kind of posts about the recent pens \\nmassacre of the devils actuallyi am  bit puzzled too and a bit relieved however i am going to put an endto nonpittsburghers \\nrelief with a bit of praise for the pens man theyare killing those devils worse than i thought jagr just showed you why \\nhe is much better than his regular season stats he is also a lotfo fun to watch in the playoffs bowman should let jagr \\nhave a lot offun in the next couple of games since the pens are going to beat the pulp out of jerseyanyway i was very \\ndisappointed not to see the islanders lose the finalregular season game pens rule\",\n",
    "  \"id\": \"1\"},\n",
    "   {\"text\": \"i am sure some bashers of pens fans are pretty confused about the lackof any kind of posts about the recent pens \\nmassacre of the devils actuallyi am  bit puzzled too and a bit relieved however i am going to put an endto nonpittsburghers \\nrelief with a bit of praise for the pens man theyare killing those devils worse than i thought jagr just showed you why \\nhe is much better than his regular season stats he is also a lotfo fun to watch in the playoffs bowman should let jagr \\nhave a lot offun in the next couple of games since the pens are going to beat the pulp out of jerseyanyway i was very \\ndisappointed not to see the islanders lose the finalregular season game pens rule\",\n",
    "  \"id\": \"1\"},\n",
    "  {\"text\": \"i am sure some bashers of pens fans are pretty confused about the lackof any kind of posts about the recent pens \\nmassacre of the devils actuallyi am  bit puzzled too and a bit relieved however i am going to put an endto nonpittsburghers \\nrelief with a bit of praise for the pens man theyare killing those devils worse than i thought jagr just showed you why \\nhe is much better than his regular season stats he is also a lotfo fun to watch in the playoffs bowman should let jagr \\nhave a lot offun in the next couple of games since the pens are going to beat the pulp out of jerseyanyway i was very \\ndisappointed not to see the islanders lose the finalregular season game pens rule\",\n",
    "  \"id\": \"1\"},\n",
    "   {\"text\": \"i am sure some bashers of pens fans are pretty confused about the lackof any kind of posts about the recent pens \\nmassacre of the devils actuallyi am  bit puzzled too and a bit relieved however i am going to put an endto nonpittsburghers \\nrelief with a bit of praise for the pens man theyare killing those devils worse than i thought jagr just showed you why \\nhe is much better than his regular season stats he is also a lotfo fun to watch in the playoffs bowman should let jagr \\nhave a lot offun in the next couple of games since the pens are going to beat the pulp out of jerseyanyway i was very \\ndisappointed not to see the islanders lose the finalregular season game pens rule\",\n",
    "  \"id\": \"1\"}\n",
    " ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1864742d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"score\": 0.16138790547847748, \"Categ\": 10, \"pred\": \"k\", \"probabs\": {\"0\": 0.045817021280527115, \"1\": 0.024176303297281265, \"2\": 0.03678528219461441, \"3\": 0.07134871929883957, \"4\": 0.048216186463832855, \"5\": 0.03441502898931503, \"6\": 0.05540027469396591, \"7\": 0.05339713767170906, \"8\": 0.04719889909029007, \"9\": 0.07552622258663177, \"10\": 0.16138790547847748, \"11\": 0.026280518621206284, \"12\": 0.059216320514678955, \"13\": 0.05626598373055458, \"14\": 0.054571881890296936, \"15\": 0.03751858323812485, \"16\": 0.03490070998668671, \"17\": 0.02578582800924778, \"18\": 0.030874980613589287, \"19\": 0.020916156470775604}, \"text\": \"i am sure some bashers of pens fans are pretty confused about the lackof any kind of posts about the recent pens \\nmassacre of the devils actuallyi am  bit puzzled too and a bit relieved however i am going to put an endto nonpittsburghers \\nrelief with a bit of praise for the pens man theyare killing those devils worse than i thought jagr just showed you why \\nhe is much better than his regular season stats he is also a lotfo fun to watch in the playoffs bowman should let jagr \\nhave a lot offun in the next couple of games since the pens are going to beat the pulp out of jerseyanyway i was very \\ndisappointed not to see the islanders lose the finalregular season game pens rule\", \"id\": \"1\"}, {\"score\": 0.2781469523906708, \"Categ\": 10, \"pred\": \"k\", \"probabs\": {\"0\": 0.03602687641978264, \"1\": 0.02990960329771042, \"2\": 0.030879518017172813, \"3\": 0.026226039975881577, \"4\": 0.028505275025963783, \"5\": 0.022405104711651802, \"6\": 0.037264756858348846, \"7\": 0.04320606589317322, \"8\": 0.04648202657699585, \"9\": 0.07691013067960739, \"10\": 0.2781469523906708, \"11\": 0.029925566166639328, \"12\": 0.027056949213147163, \"13\": 0.051986150443553925, \"14\": 0.031988438218832016, \"15\": 0.03445671498775482, \"16\": 0.03516422212123871, \"17\": 0.05517290532588959, \"18\": 0.04007987305521965, \"19\": 0.03820694237947464}, \"text\": \"i am sure some bashers of pens fans are pretty confused about the lackof any kind of posts about the recent pens \\nmassacre of the devils actuallyi am  bit puzzled too and a bit relieved however i am going to put an endto nonpittsburghers \\nrelief with a bit of praise for the pens man theyare killing those devils worse than i thought jagr just showed you why \\nhe is much better than his regular season stats he is also a lotfo fun to watch in the playoffs bowman should let jagr \\nhave a lot offun in the next couple of games since the pens are going to beat the pulp out of jerseyanyway i was very \\ndisappointed not to see the islanders lose the finalregular season game pens rule\", \"id\": \"1\"}, {\"score\": 0.18046844005584717, \"Categ\": 10, \"pred\": \"k\", \"probabs\": {\"0\": 0.06516445428133011, \"1\": 0.033760424703359604, \"2\": 0.03956637158989906, \"3\": 0.034186530858278275, \"4\": 0.02500721998512745, \"5\": 0.03805510699748993, \"6\": 0.021311122924089432, \"7\": 0.04094310477375984, \"8\": 0.03846709057688713, \"9\": 0.1367383450269699, \"10\": 0.18046844005584717, \"11\": 0.03968806564807892, \"12\": 0.025386633351445198, \"13\": 0.05218673124909401, \"14\": 0.01929749920964241, \"15\": 0.04014987498521805, \"16\": 0.03949611261487007, \"17\": 0.05749516189098358, \"18\": 0.04695656895637512, \"19\": 0.025675099343061447}, \"text\": \"i am sure some bashers of pens fans are pretty confused about the lackof any kind of posts about the recent pens \\nmassacre of the devils actuallyi am  bit puzzled too and a bit relieved however i am going to put an endto nonpittsburghers \\nrelief with a bit of praise for the pens man theyare killing those devils worse than i thought jagr just showed you why \\nhe is much better than his regular season stats he is also a lotfo fun to watch in the playoffs bowman should let jagr \\nhave a lot offun in the next couple of games since the pens are going to beat the pulp out of jerseyanyway i was very \\ndisappointed not to see the islanders lose the finalregular season game pens rule\", \"id\": \"1\"}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://hxr7tn32b0.execute-api.us-east-2.amazonaws.com/demo1\"\n",
    "\n",
    "payload = json.dumps([\n",
    "  {\n",
    "    \"text\": \"i am sure some bashers of pens fans are pretty confused about the lackof any kind of posts about the recent pens \\nmassacre of the devils actuallyi am  bit puzzled too and a bit relieved however i am going to put an endto nonpittsburghers \\nrelief with a bit of praise for the pens man theyare killing those devils worse than i thought jagr just showed you why \\nhe is much better than his regular season stats he is also a lotfo fun to watch in the playoffs bowman should let jagr \\nhave a lot offun in the next couple of games since the pens are going to beat the pulp out of jerseyanyway i was very \\ndisappointed not to see the islanders lose the finalregular season game pens rule\",\n",
    "    \"id\": \"1\"\n",
    "  }\n",
    "])\n",
    "headers = {\n",
    "  'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a6739b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1155bd27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
